{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "979c0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.41.1\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luluk\\appdata\\roaming\\python\\python313\\site-packages (from transformers==4.41.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (2.32.5)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.1)\n",
      "  Downloading tokenizers-0.19.1.tar.gz (321 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers==4.41.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.1) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.1) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\luluk\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers==4.41.1) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers==4.41.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers==4.41.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers==4.41.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luluk\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers==4.41.1) (2025.10.5)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 6.3/9.1 MB 38.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 24.3 MB/s  0:00:00\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [106 lines of output]\n",
      "      Running `maturin pep517 build-wheel -i C:\\Users\\luluk\\AppData\\Local\\Programs\\Python\\Python313\\python.exe --compatibility off`\n",
      "      âš ï¸\\x8f  Warning: `project.version` field is required in pyproject.toml unless it is present in the `project.dynamic` list\n",
      "      ðŸ\\x8d¹ Building a mixed python/rust project\n",
      "      ðŸ”— Found pyo3 bindings\n",
      "      ðŸ\\x90\\x8d Found CPython 3.13 at C:\\Users\\luluk\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n",
      "      ðŸ“¡ Using build options features, bindings from pyproject.toml\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m proc-macro2 v1.0.81\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m unicode-ident v1.0.12\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m autocfg v1.2.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m target-lexicon v0.12.14\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m windows_x86_64_msvc v0.52.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m once_cell v1.19.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m libc v0.2.153\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m cfg-if v1.0.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m crossbeam-utils v0.8.19\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m memchr v2.7.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m cc v1.0.94\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m windows_x86_64_msvc v0.48.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m ident_case v1.0.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m fnv v1.0.7\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m strsim v0.10.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m serde v1.0.198\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m portable-atomic v1.6.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m smallvec v1.13.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m regex-syntax v0.8.3\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m either v1.11.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m rayon-core v1.12.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m parking_lot_core v0.9.9\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m num-traits v0.2.18\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m lock_api v0.4.11\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m pkg-config v0.3.30\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m aho-corasick v1.1.3\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m matrixmultiply v0.3.8\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m memoffset v0.9.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m getrandom v0.2.14\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m heck v0.4.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m onig_sys v69.8.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m windows-targets v0.52.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m windows-targets v0.48.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m regex-automata v0.4.6\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m windows-sys v0.52.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m scopeguard v1.2.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m paste v1.0.14\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m rand_core v0.6.4\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-build-config v0.21.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m quote v1.0.36\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m crossbeam-epoch v0.9.18\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m esaxx-rs v0.1.10\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m minimal-lexical v0.2.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m utf8parse v0.2.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m ppv-lite86 v0.2.17\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m syn v2.0.60\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m encode_unicode v0.3.6\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m serde_json v1.0.116\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m thiserror v1.0.58\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m lazy_static v1.4.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m anstyle v1.0.6\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m unicode-width v0.1.11\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m rawpointer v0.2.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m crossbeam-deque v0.8.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m log v0.4.21\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m anstyle-query v1.0.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m anstyle-wincon v3.0.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m console v0.15.8\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m nom v7.1.3\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m rand_chacha v0.3.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m anstyle-parse v0.2.3\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m num-complex v0.4.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m num-integer v0.1.46\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m parking_lot v0.12.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m rayon v1.10.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m itertools v0.11.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m base64 v0.13.1\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m macro_rules_attribute-proc_macro v0.2.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m unicode-segmentation v1.11.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m regex v1.10.4\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m unindent v0.2.3\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m pyo3-ffi v0.21.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m pyo3 v0.21.2\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m indoc v2.0.5\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m itoa v1.0.11\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m number_prefix v0.4.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m ryu v1.0.17\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m colorchoice v1.0.0\n",
      "      \u001b[1m\u001b[32m   Compiling\u001b[0m bitflags v1.3.2\n",
      "      \u001b[1m\u001b[31merror\u001b[0m\u001b[1m:\u001b[0m failed to run custom build command for `pyo3-ffi v0.21.2`\n",
      "      \n",
      "      Caused by:\n",
      "        process didn't exit successfully: `C:\\Users\\luluk\\AppData\\Local\\Temp\\pip-install-tkiuwzdy\\tokenizers_23b7f7263e464c78a4e4305386ce2ba8\\bindings\\python\\target\\release\\build\\pyo3-ffi-4e54b626628dfb99\\build-script-build` (exit code: 1)\n",
      "        --- stdout\n",
      "        cargo:rerun-if-env-changed=PYO3_CROSS\n",
      "        cargo:rerun-if-env-changed=PYO3_CROSS_LIB_DIR\n",
      "        cargo:rerun-if-env-changed=PYO3_CROSS_PYTHON_VERSION\n",
      "        cargo:rerun-if-env-changed=PYO3_CROSS_PYTHON_IMPLEMENTATION\n",
      "        cargo:rerun-if-env-changed=PYO3_PRINT_CONFIG\n",
      "        cargo:rerun-if-env-changed=PYO3_USE_ABI3_FORWARD_COMPATIBILITY\n",
      "      \n",
      "        --- stderr\n",
      "        error: the configured Python interpreter version (3.13) is newer than PyO3's maximum supported version (3.12)\n",
      "        = help: please check if an updated version of PyO3 is available. Current version: 0.21.2\n",
      "        = help: set PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1 to suppress this check and build anyway using the stable ABI\n",
      "      \u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m:\u001b[0m build failed, waiting for other jobs to finish...\n",
      "      ðŸ’¥ maturin failed\n",
      "        Caused by: Failed to build a native library through cargo\n",
      "        Caused by: Cargo build finished with \"exit code: 101\": `\"cargo\" \"rustc\" \"--features\" \"pyo3/extension-module\" \"--message-format\" \"json-render-diagnostics\" \"--manifest-path\" \"C:\\\\Users\\\\luluk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-tkiuwzdy\\\\tokenizers_23b7f7263e464c78a4e4305386ce2ba8\\\\bindings\\\\python\\\\Cargo.toml\" \"--release\" \"--lib\"`\n",
      "      Error: command ['maturin', 'pep517', 'build-wheel', '-i', 'C:\\\\Users\\\\luluk\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe', '--compatibility', 'off'] returned non-zero exit status 1\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> tokenizers\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers==4.41.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1972bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce49c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "GPU is available.\n",
      "Number of GPUs: 1\n",
      "Current GPU name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available. PyTorch will use CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71b04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/jojo-ai-mst/Roleplay-Indonesian/GPTeacher RolePlay Simple Deduped - Indonesian.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fcb066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>petunjuk</th>\n",
       "      <th>masukan</th>\n",
       "      <th>tanggapan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine you are a detective trying to solve a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The scene of the crime is a dimly lit study in...</td>\n",
       "      <td>Bayangkan Anda adalah seorang detektif yang me...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>TKP adalah sebuah ruang belajar remang-remang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are an alien diplomat visiting Earth for t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My initial impressions of Earth are dominated ...</td>\n",
       "      <td>Anda adalah seorang diplomat asing yang mengun...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Kesan awal saya terhadap Bumi didominasi oleh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imagine you are an ambassador from a planet ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greetings, esteemed Earth leaders. I am the am...</td>\n",
       "      <td>Bayangkan Anda adalah seorang duta besar dari ...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Salam, para pemimpin Bumi yang terhormat. Saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretend you are a detective in the 1920s inter...</td>\n",
       "      <td>The witness claims to have seen the suspect fl...</td>\n",
       "      <td>1. Can you describe the suspect's appearance, ...</td>\n",
       "      <td>Anggaplah Anda adalah seorang detektif di tahu...</td>\n",
       "      <td>Saksi mengaku melihat tersangka melarikan diri...</td>\n",
       "      <td>1. Bisakah Anda menjelaskan penampilan tersang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a time traveler from the 30th century,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Fossil fuel-based transportation: In the 30...</td>\n",
       "      <td>Anda adalah penjelajah waktu dari abad ke-30, ...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>1. Transportasi berbasis bahan bakar fosil: Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>You are the president of a fictional country c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My dear citizens of Estoria, I stand before yo...</td>\n",
       "      <td>Anda adalah presiden negara fiksi bernama Esto...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Warga Estoria yang terkasih, saya berdiri di h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>You are renowned historian Dr. Isabella Wright...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The invention of the printing press revolution...</td>\n",
       "      <td>Anda adalah sejarawan terkenal Dr. Isabella Wr...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Penemuan mesin cetak merevolusi sejarah manusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>Role play as Dolly Parton, a famous singer-son...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My inspiration for the Imagination Library pro...</td>\n",
       "      <td>Bermain peran sebagai Dolly Parton, penyanyi-p...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Inspirasi saya untuk proyek Perpustakaan Imaji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>You are a renowned historian specializing in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sumerian culture, originating in ancient M...</td>\n",
       "      <td>Anda adalah seorang sejarawan terkenal yang be...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Kebudayaan Sumeria, yang berasal dari Mesopota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>You are a powerful wizard living in a magical ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To create a potion for communicating with anim...</td>\n",
       "      <td>Anda adalah seorang penyihir kuat yang tinggal...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>Untuk membuat ramuan untuk berkomunikasi denga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruction  \\\n",
       "0     Imagine you are a detective trying to solve a ...   \n",
       "1     You are an alien diplomat visiting Earth for t...   \n",
       "2     Imagine you are an ambassador from a planet ca...   \n",
       "3     Pretend you are a detective in the 1920s inter...   \n",
       "4     You are a time traveler from the 30th century,...   \n",
       "...                                                 ...   \n",
       "1918  You are the president of a fictional country c...   \n",
       "1919  You are renowned historian Dr. Isabella Wright...   \n",
       "1920  Role play as Dolly Parton, a famous singer-son...   \n",
       "1921  You are a renowned historian specializing in a...   \n",
       "1922  You are a powerful wizard living in a magical ...   \n",
       "\n",
       "                                                  input  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     The witness claims to have seen the suspect fl...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1918                                                NaN   \n",
       "1919                                                NaN   \n",
       "1920                                                NaN   \n",
       "1921                                                NaN   \n",
       "1922                                                NaN   \n",
       "\n",
       "                                               response  \\\n",
       "0     The scene of the crime is a dimly lit study in...   \n",
       "1     My initial impressions of Earth are dominated ...   \n",
       "2     Greetings, esteemed Earth leaders. I am the am...   \n",
       "3     1. Can you describe the suspect's appearance, ...   \n",
       "4     1. Fossil fuel-based transportation: In the 30...   \n",
       "...                                                 ...   \n",
       "1918  My dear citizens of Estoria, I stand before yo...   \n",
       "1919  The invention of the printing press revolution...   \n",
       "1920  My inspiration for the Imagination Library pro...   \n",
       "1921  The Sumerian culture, originating in ancient M...   \n",
       "1922  To create a potion for communicating with anim...   \n",
       "\n",
       "                                               petunjuk  \\\n",
       "0     Bayangkan Anda adalah seorang detektif yang me...   \n",
       "1     Anda adalah seorang diplomat asing yang mengun...   \n",
       "2     Bayangkan Anda adalah seorang duta besar dari ...   \n",
       "3     Anggaplah Anda adalah seorang detektif di tahu...   \n",
       "4     Anda adalah penjelajah waktu dari abad ke-30, ...   \n",
       "...                                                 ...   \n",
       "1918  Anda adalah presiden negara fiksi bernama Esto...   \n",
       "1919  Anda adalah sejarawan terkenal Dr. Isabella Wr...   \n",
       "1920  Bermain peran sebagai Dolly Parton, penyanyi-p...   \n",
       "1921  Anda adalah seorang sejarawan terkenal yang be...   \n",
       "1922  Anda adalah seorang penyihir kuat yang tinggal...   \n",
       "\n",
       "                                                masukan  \\\n",
       "0                                               #VALUE!   \n",
       "1                                               #VALUE!   \n",
       "2                                               #VALUE!   \n",
       "3     Saksi mengaku melihat tersangka melarikan diri...   \n",
       "4                                               #VALUE!   \n",
       "...                                                 ...   \n",
       "1918                                            #VALUE!   \n",
       "1919                                            #VALUE!   \n",
       "1920                                            #VALUE!   \n",
       "1921                                            #VALUE!   \n",
       "1922                                            #VALUE!   \n",
       "\n",
       "                                              tanggapan  \n",
       "0     TKP adalah sebuah ruang belajar remang-remang ...  \n",
       "1     Kesan awal saya terhadap Bumi didominasi oleh ...  \n",
       "2     Salam, para pemimpin Bumi yang terhormat. Saya...  \n",
       "3     1. Bisakah Anda menjelaskan penampilan tersang...  \n",
       "4     1. Transportasi berbasis bahan bakar fosil: Pa...  \n",
       "...                                                 ...  \n",
       "1918  Warga Estoria yang terkasih, saya berdiri di h...  \n",
       "1919  Penemuan mesin cetak merevolusi sejarah manusi...  \n",
       "1920  Inspirasi saya untuk proyek Perpustakaan Imaji...  \n",
       "1921  Kebudayaan Sumeria, yang berasal dari Mesopota...  \n",
       "1922  Untuk membuat ramuan untuk berkomunikasi denga...  \n",
       "\n",
       "[1923 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618f0ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1480)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"input\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999b830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 'instruksi' and 'konteks' into a single 'prompt'...\n",
      "...Done!\n",
      "\n",
      "--- Final Cleaned DataFrame (First 5 Rows) ---\n",
      "                                              prompt  \\\n",
      "0  Bayangkan Anda adalah seorang detektif yang me...   \n",
      "1  Anda adalah seorang diplomat asing yang mengun...   \n",
      "2  Bayangkan Anda adalah seorang duta besar dari ...   \n",
      "3  Anggaplah Anda adalah seorang detektif di tahu...   \n",
      "4  Anda adalah penjelajah waktu dari abad ke-30, ...   \n",
      "\n",
      "                                             respons  \n",
      "0  TKP adalah sebuah ruang belajar remang-remang ...  \n",
      "1  Kesan awal saya terhadap Bumi didominasi oleh ...  \n",
      "2  Salam, para pemimpin Bumi yang terhormat. Saya...  \n",
      "3  1. Bisakah Anda menjelaskan penampilan tersang...  \n",
      "4  1. Transportasi berbasis bahan bakar fosil: Pa...  \n",
      "\n",
      "\n",
      "--- Example of a Combined Prompt (from row 0) ---\n",
      "Anggaplah Anda adalah seorang detektif di tahun 1920-an yang mewawancarai seorang saksi kejahatan. Ajukan 5 pertanyaan untuk mengumpulkan informasi tentang tersangka.\n",
      "\n",
      "Saksi mengaku melihat tersangka melarikan diri dari lokasi kejadian dengan membawa barang curian.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- 1. Identify all three columns we need ---\n",
    "    indonesian_response_col = df.columns[5] # The 6th column\n",
    "    \n",
    "    # Select the three Indonesian columns\n",
    "    clean_df = df[['petunjuk', 'masukan', indonesian_response_col]].copy()\n",
    "\n",
    "    # --- 2. Rename columns for clarity ---\n",
    "    clean_df.rename(columns={\n",
    "        'petunjuk': 'instruksi', # Renamed to avoid confusion with final 'prompt'\n",
    "        'masukan': 'konteks',\n",
    "        indonesian_response_col: 'respons'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # --- 3. Clean the 'konteks' (masukan) column ---\n",
    "    # Replace the text \"#VALUE!\" with a proper null value (np.nan)\n",
    "    clean_df['konteks'] = clean_df['konteks'].replace(\"#VALUE!\", np.nan)\n",
    "\n",
    "    # --- 4. Define our prompt-building function ---\n",
    "    def create_full_prompt(row):\n",
    "        instruksi = row['instruksi']\n",
    "        konteks = row['konteks']\n",
    "        \n",
    "        # Check if kontek is NaN, None, or an empty string\n",
    "        if pd.isna(konteks) or konteks.strip() == \"\":\n",
    "            return instruksi # Use instruction only\n",
    "        else:\n",
    "            # Combine them using our template\n",
    "            return f\"{instruksi}\\n\\n{konteks}\"\n",
    "\n",
    "    # --- 5. Apply the function to create the final 'prompt' column ---\n",
    "    print(\"Combining 'instruksi' and 'konteks' into a single 'prompt'...\")\n",
    "    clean_df['prompt'] = clean_df.apply(create_full_prompt, axis=1)\n",
    "    print(\"...Done!\\n\")\n",
    "\n",
    "    # --- 6. Create our final DataFrame ---\n",
    "    # We only need the new 'prompt' and the 'respons'\n",
    "    final_df = clean_df[['prompt', 'respons']].copy()\n",
    "\n",
    "    # Drop any rows where the final prompt or response is missing\n",
    "    final_df.dropna(inplace=True)\n",
    "\n",
    "    # --- 7. Show the results ---\n",
    "    print(\"--- Final Cleaned DataFrame (First 5 Rows) ---\")\n",
    "    print(final_df.head())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # --- 8. Show an example of a combined prompt ---\n",
    "    # Find a row where 'konteks' was NOT empty to prove it worked\n",
    "    combined_example_row = clean_df[clean_df['konteks'].notnull()]\n",
    "    \n",
    "    if not combined_example_row.empty:\n",
    "        print(\"--- Example of a Combined Prompt (from row 0) ---\")\n",
    "        print(combined_example_row.iloc[0]['prompt'])\n",
    "    else:\n",
    "        print(\"Could not find a combined prompt example in the first batch.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4bfa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruksi</th>\n",
       "      <th>konteks</th>\n",
       "      <th>respons</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayangkan Anda adalah seorang detektif yang me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TKP adalah sebuah ruang belajar remang-remang ...</td>\n",
       "      <td>Bayangkan Anda adalah seorang detektif yang me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anda adalah seorang diplomat asing yang mengun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kesan awal saya terhadap Bumi didominasi oleh ...</td>\n",
       "      <td>Anda adalah seorang diplomat asing yang mengun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayangkan Anda adalah seorang duta besar dari ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salam, para pemimpin Bumi yang terhormat. Saya...</td>\n",
       "      <td>Bayangkan Anda adalah seorang duta besar dari ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anggaplah Anda adalah seorang detektif di tahu...</td>\n",
       "      <td>Saksi mengaku melihat tersangka melarikan diri...</td>\n",
       "      <td>1. Bisakah Anda menjelaskan penampilan tersang...</td>\n",
       "      <td>Anggaplah Anda adalah seorang detektif di tahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anda adalah penjelajah waktu dari abad ke-30, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Transportasi berbasis bahan bakar fosil: Pa...</td>\n",
       "      <td>Anda adalah penjelajah waktu dari abad ke-30, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Anda adalah presiden negara fiksi bernama Esto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warga Estoria yang terkasih, saya berdiri di h...</td>\n",
       "      <td>Anda adalah presiden negara fiksi bernama Esto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>Anda adalah sejarawan terkenal Dr. Isabella Wr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penemuan mesin cetak merevolusi sejarah manusi...</td>\n",
       "      <td>Anda adalah sejarawan terkenal Dr. Isabella Wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>Bermain peran sebagai Dolly Parton, penyanyi-p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inspirasi saya untuk proyek Perpustakaan Imaji...</td>\n",
       "      <td>Bermain peran sebagai Dolly Parton, penyanyi-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>Anda adalah seorang sejarawan terkenal yang be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kebudayaan Sumeria, yang berasal dari Mesopota...</td>\n",
       "      <td>Anda adalah seorang sejarawan terkenal yang be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>Anda adalah seorang penyihir kuat yang tinggal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Untuk membuat ramuan untuk berkomunikasi denga...</td>\n",
       "      <td>Anda adalah seorang penyihir kuat yang tinggal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruksi  \\\n",
       "0     Bayangkan Anda adalah seorang detektif yang me...   \n",
       "1     Anda adalah seorang diplomat asing yang mengun...   \n",
       "2     Bayangkan Anda adalah seorang duta besar dari ...   \n",
       "3     Anggaplah Anda adalah seorang detektif di tahu...   \n",
       "4     Anda adalah penjelajah waktu dari abad ke-30, ...   \n",
       "...                                                 ...   \n",
       "1918  Anda adalah presiden negara fiksi bernama Esto...   \n",
       "1919  Anda adalah sejarawan terkenal Dr. Isabella Wr...   \n",
       "1920  Bermain peran sebagai Dolly Parton, penyanyi-p...   \n",
       "1921  Anda adalah seorang sejarawan terkenal yang be...   \n",
       "1922  Anda adalah seorang penyihir kuat yang tinggal...   \n",
       "\n",
       "                                                konteks  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     Saksi mengaku melihat tersangka melarikan diri...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1918                                                NaN   \n",
       "1919                                                NaN   \n",
       "1920                                                NaN   \n",
       "1921                                                NaN   \n",
       "1922                                                NaN   \n",
       "\n",
       "                                                respons  \\\n",
       "0     TKP adalah sebuah ruang belajar remang-remang ...   \n",
       "1     Kesan awal saya terhadap Bumi didominasi oleh ...   \n",
       "2     Salam, para pemimpin Bumi yang terhormat. Saya...   \n",
       "3     1. Bisakah Anda menjelaskan penampilan tersang...   \n",
       "4     1. Transportasi berbasis bahan bakar fosil: Pa...   \n",
       "...                                                 ...   \n",
       "1918  Warga Estoria yang terkasih, saya berdiri di h...   \n",
       "1919  Penemuan mesin cetak merevolusi sejarah manusi...   \n",
       "1920  Inspirasi saya untuk proyek Perpustakaan Imaji...   \n",
       "1921  Kebudayaan Sumeria, yang berasal dari Mesopota...   \n",
       "1922  Untuk membuat ramuan untuk berkomunikasi denga...   \n",
       "\n",
       "                                                 prompt  \n",
       "0     Bayangkan Anda adalah seorang detektif yang me...  \n",
       "1     Anda adalah seorang diplomat asing yang mengun...  \n",
       "2     Bayangkan Anda adalah seorang duta besar dari ...  \n",
       "3     Anggaplah Anda adalah seorang detektif di tahu...  \n",
       "4     Anda adalah penjelajah waktu dari abad ke-30, ...  \n",
       "...                                                 ...  \n",
       "1918  Anda adalah presiden negara fiksi bernama Esto...  \n",
       "1919  Anda adalah sejarawan terkenal Dr. Isabella Wr...  \n",
       "1920  Bermain peran sebagai Dolly Parton, penyanyi-p...  \n",
       "1921  Anda adalah seorang sejarawan terkenal yang be...  \n",
       "1922  Anda adalah seorang penyihir kuat yang tinggal...  \n",
       "\n",
       "[1923 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92fc159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "Bayangkan Anda adalah seorang detektif yang mencoba memecahkan misteri pembunuhan di kota fiksi era Victoria. Jelaskan TKP, tersangka utama, dan rencana Anda untuk menyelidiki kasus tersebut.\n",
      "\n",
      "respons:\n",
      "TKP adalah sebuah ruang belajar remang-remang di dalam sebuah rumah megah era Victoria. Ada meja kayu ek besar di tengah ruangan, dan almarhum, Lord Barrington, terbaring lemas di atasnya dengan luka tembak di dada. Kaca jendela yang pecah menandakan kemungkinan masuknya penyerang. Tiga tersangka utama adalah: 1) Lady Barrington, istri korban, yang semakin sering berselisih dengan suaminya; 2) Randall, kepala pelayan setia keluarga, yang baru-baru ini mengetahui bahwa dia akan digantikan; dan 3) Edgar, sepupu jauh, yang mengharapkan warisan besar jika Lord Barrington meninggal. Rencana saya untuk menyelidiki kasus ini meliputi: mewawancarai setiap tersangka tentang keberadaan mereka selama kejahatan terjadi; memeriksa jendela yang pecah untuk mencari sidik jari atau tanda-tanda masuk secara paksa; dan menganalisis senjata pembunuh, pistol, untuk melacak kepemilikannya dan mencari bukti tambahan seperti sebagian sidik jari atau jejak lain yang ditinggalkan oleh pelakunya.\n",
      "\n",
      "\n",
      "prompt:\n",
      "Anda adalah seorang diplomat asing yang mengunjungi Bumi untuk pertama kalinya dari planet yang berteknologi maju. Jelaskan kesan pertama Anda terhadap Bumi, masyarakat kita, dan teknologi yang Anda lihat.\n",
      "\n",
      "respons:\n",
      "Kesan awal saya terhadap Bumi didominasi oleh keindahan alam planet ini dan beragamnya budaya dan masyarakat di seluruh permukaannya. Medan bumi, mulai dari hutan lebat dan pegunungan hingga lautan dan gurun yang luas, memikat dan membuat saya penasaran. Jika diteliti lebih dekat, masyarakat manusia menunjukkan spektrum kepercayaan, nilai, dan tradisi yang luas, yang berkontribusi pada rumitnya kehidupan umat manusia. Namun, saya mengamati bahwa keanekaragaman ini terkadang dapat menjadi sumber konflik dan perpecahan di antara spesies. Berkenaan dengan teknologi, bumi tampaknya berada pada jalur progresif menuju kemajuan di berbagai sektor, seperti energi terbarukan, transportasi, dan komunikasi. Namun, hal ini masih tertinggal dibandingkan dengan kemampuan bumi, karena penggunaan bahan bakar fosil, polusi, dan pengelolaan sumber daya yang tidak efisien masih banyak terjadi. Sebagai diplomat tamu, saya ingin belajar lebih banyak tentang Bumi dan masyarakatnya, dan melihat apakah ada peluang untuk kolaborasi dan pertukaran antara kedua dunia.\n",
      "\n",
      "\n",
      "prompt:\n",
      "Bayangkan Anda adalah seorang duta besar dari sebuah planet bernama Zogaria, dan tulislah pidato yang memperkenalkan planet Anda dan budayanya kepada para pemimpin Bumi.\n",
      "\n",
      "respons:\n",
      "Salam, para pemimpin Bumi yang terhormat. Saya adalah duta besar dari planet Zogaria yang jauh, negeri yang penuh keindahan, inovasi, dan harmoni. Dunia kita penuh dengan pemandangan yang beragam – mulai dari lautan biru jernih di Azuron hingga hutan Emeraldia yang rimbun dan menjulang tinggi, keindahan Zogaria yang mempesona sama beragamnya dengan penghuninya. Kami, Zogarian, percaya pada hidup selaras dengan planet kita, melindungi sumber dayanya, dan berbagi kemakmuran dengan semua makhluk hidup. Masyarakat kita menghargai pendidikan, kreativitas, dan keberlanjutan, dengan kemajuan dalam energi bersih, habitat ramah lingkungan, dan teknologi yang meningkatkan kehidupan kita sehari-hari. Sebagai federasi persatuan dari berbagai wilayah, kami merayakan perbedaan budaya dan berkolaborasi dalam proyek yang mendorong pembangunan dan persatuan. Hari ini, kami hadir di hadapan Anda dalam semangat persahabatan, bersemangat untuk berbagi pengetahuan dan kekayaan budaya untuk memajukan perdamaian dan kemakmuran antara kedua dunia.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'prompt:\\n{clean_df[\"prompt\"][i]}\\n')\n",
    "    print(f'respons:\\n{clean_df[\"respons\"][i]}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d354635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: cahya/gpt2-small-indonesian-522M\n",
      "...Tokenizer loaded.\n",
      "Added 1 new special token(s).\n",
      "New vocabulary size: 50258\n",
      "\n",
      "--- Tokenizer Test ---\n",
      "Original Text:\n",
      "Anda adalah seorang detektif.Tentu, apa kasusnya?<|endoftext|>\n",
      "\n",
      "Tokenized IDs:\n",
      "[20976, 360, 604, 17645, 14, 52, 1032, 12, 1985, 40326, 31, 0]\n",
      "Token count: 12\n",
      "\n",
      "Decoded Text:\n",
      "Anda adalah seorang detektif.Tentu, apa kasusnya?<|endoftext|>\n",
      "\n",
      "--- Special Token Verification ---\n",
      "EOS token: '<|endoftext|>' -> ID: 0\n",
      "PAD token: '<|pad|>' -> ID: 50257\n",
      "\n",
      "Success! EOS and PAD tokens have different IDs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "MODEL_NAME = \"cahya/gpt2-small-indonesian-522M\"\n",
    "\n",
    "print(f\"Loading tokenizer: {MODEL_NAME}\")\n",
    "\n",
    "# 1. Load the tokenizer.\n",
    "# We use use_fast=False to load the Python-based \"slow\" tokenizer.\n",
    "# This avoids a known bug in new 'transformers' versions that\n",
    "# incorrectly look for a 'additional_chat_templates' file.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    use_fast=False\n",
    ")\n",
    "print(\"...Tokenizer loaded.\")\n",
    "\n",
    "# 2. Define and add special tokens.\n",
    "# The model's existing End-of-Sequence token is '<|endoftext|>' (ID 0).\n",
    "# We add a new, dedicated token for padding.\n",
    "special_tokens_dict = {\n",
    "    'eos_token': '<|endoftext|>',\n",
    "    'pad_token': '<|pad|>'\n",
    "}\n",
    "\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(f\"Added {num_added_toks} new special token(s).\")\n",
    "\n",
    "# 3. Store the final vocabulary size.\n",
    "# We will need this number later when we build our model's embedding layer.\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print(f\"New vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "\n",
    "# 4. --- Real Tokenizer Test ---\n",
    "print(\"\\n--- Tokenizer Test ---\")\n",
    "\n",
    "# Use a real example from our roleplay dataset\n",
    "prompt = \"Anda adalah seorang detektif.\"\n",
    "response = \"Tentu, apa kasusnya?\"\n",
    "\n",
    "# This is the final format our model will be trained on:\n",
    "# [PROMPT_TOKENS] + [RESPONSE_TOKENS] + [EOS_TOKEN]\n",
    "full_text = prompt + response + tokenizer.eos_token\n",
    "\n",
    "print(f\"Original Text:\\n{full_text}\")\n",
    "\n",
    "# Tokenize the text into a list of numbers\n",
    "input_ids = tokenizer(full_text)['input_ids']\n",
    "\n",
    "print(f\"\\nTokenized IDs:\\n{input_ids}\")\n",
    "print(f\"Token count: {len(input_ids)}\")\n",
    "\n",
    "# Decode the numbers back to text to verify\n",
    "decoded_text = tokenizer.decode(input_ids)\n",
    "print(f\"\\nDecoded Text:\\n{decoded_text}\")\n",
    "\n",
    "\n",
    "# 5. --- Special Token Verification ---\n",
    "print(\"\\n--- Special Token Verification ---\")\n",
    "eos_id = tokenizer.eos_token_id\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "print(f\"EOS token: '{tokenizer.eos_token}' -> ID: {eos_id}\")\n",
    "print(f\"PAD token: '{tokenizer.pad_token}' -> ID: {pad_id}\")\n",
    "\n",
    "# This is the most critical check:\n",
    "# We must ensure the PAD token and EOS token have different IDs.\n",
    "assert eos_id != pad_id\n",
    "print(\"\\nSuccess! EOS and PAD tokens have different IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca422099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New (Robust) Dataset Test ---\n",
      "Sample 0:\n",
      "\n",
      "Input IDs:\n",
      "tensor([   53,  3188,    26,  1545,  2865,  5126,   360,   604, 17645,   288,\n",
      "         3192,  9710,  7724,  5344,   273,   675,  5355,  3832,  8428,    14,\n",
      "          378,  3032,   340,  7207,    12, 15532,  1057,    12,   287,  3761,\n",
      "         5126,   369, 11877,  2847,   490,    14,   199,   199, 19507,    26,\n",
      "          221,    52,  7207,   360,   504,  2404,  2488,  3850,   264,    13,\n",
      "         7583,   264,   273,   370,   504,  1116, 18470,  3832,  8428,    14,\n",
      "         2602,  8399,   653,  1414,   634,   273,  2122,  5805,    12,   287,\n",
      "        16144,    12,  9835,   840, 31727,    12, 35684,  2704,   275,   273,\n",
      "        10656,   348,  6540, 13661,   273, 10245,    14, 32207, 10427,   288,\n",
      "         7604,  9877,  3206, 11410,  9436,    14,  5238, 15532,  1057,   360,\n",
      "           26,   333,     9, 13280,   840, 31727,    12,  3371,  3743,    12,\n",
      "          288,  2317,  1260, 22771,   348,  5568,    27,   365,     9, 39620,\n",
      "         4769,    12,  1954, 10159,  7713,  1506,    12,   288,   883,    13,\n",
      "         5804,   329,  3820,   554,   815,   606,  3872,    27,   287,   591,\n",
      "            9, 18805,    12, 11796,  2043,    12,   288, 16700,  7796,   634,\n",
      "         1899,  9835,   840, 31727,  1229,    14, 11518,  2510,   369, 11877,\n",
      "         2847,   329,  2269,    26, 31337,  1373, 15532,  1097,  4865,   524,\n",
      "          920,  5766,  1148,    27, 13093, 10427,   288,  7604,   369,  2685,\n",
      "        32804,  7547,   466,  3812,    13, 10393,  1450,   635, 10208,    27,\n",
      "          287, 15089,  2869, 10533,    12, 13726,    12,   369, 17805, 45116,\n",
      "          287,  2685,  4268,  3413,   611,  1421, 32804,  7547,   466,  9897,\n",
      "          531,   288,  8636,   400, 33721,    14,     0])\n",
      "\n",
      "Labels (with -100 mask):\n",
      "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,    52,  7207,   360,   504,  2404,  2488,  3850,   264,    13,\n",
      "         7583,   264,   273,   370,   504,  1116, 18470,  3832,  8428,    14,\n",
      "         2602,  8399,   653,  1414,   634,   273,  2122,  5805,    12,   287,\n",
      "        16144,    12,  9835,   840, 31727,    12, 35684,  2704,   275,   273,\n",
      "        10656,   348,  6540, 13661,   273, 10245,    14, 32207, 10427,   288,\n",
      "         7604,  9877,  3206, 11410,  9436,    14,  5238, 15532,  1057,   360,\n",
      "           26,   333,     9, 13280,   840, 31727,    12,  3371,  3743,    12,\n",
      "          288,  2317,  1260, 22771,   348,  5568,    27,   365,     9, 39620,\n",
      "         4769,    12,  1954, 10159,  7713,  1506,    12,   288,   883,    13,\n",
      "         5804,   329,  3820,   554,   815,   606,  3872,    27,   287,   591,\n",
      "            9, 18805,    12, 11796,  2043,    12,   288, 16700,  7796,   634,\n",
      "         1899,  9835,   840, 31727,  1229,    14, 11518,  2510,   369, 11877,\n",
      "         2847,   329,  2269,    26, 31337,  1373, 15532,  1097,  4865,   524,\n",
      "          920,  5766,  1148,    27, 13093, 10427,   288,  7604,   369,  2685,\n",
      "        32804,  7547,   466,  3812,    13, 10393,  1450,   635, 10208,    27,\n",
      "          287, 15089,  2869, 10533,    12, 13726,    12,   369, 17805, 45116,\n",
      "          287,  2685,  4268,  3413,   611,  1421, 32804,  7547,   466,  9897,\n",
      "          531,   288,  8636,   400, 33721,    14,     0])\n",
      "\n",
      "--- Decoded Verification ---\n",
      "\n",
      "Decoded Input:\n",
      "'User: Bayangkan Anda adalah seorang detektif yang mencoba memecahkan misteri pembunuhan di kota fiksi era Victoria. Jelaskan TKP, tersangka utama, dan rencana Anda untuk menyelidiki kasus tersebut.\n",
      "\n",
      "Model: TKP adalah sebuah ruang belajar remang-remang di dalam sebuah rumah megah era Victoria. Ada meja kayu ek besar di tengah ruangan, dan almarhum, Lord Barrington, terbaring lemas di atasnya dengan luka tembak di dada. Kaca jendela yang pecah menandakan kemungkinan masuknya penyerang. Tiga tersangka utama adalah: 1) Lady Barrington, istri korban, yang semakin sering berselisih dengan suaminya; 2) Randall, kepala pelayan setia keluarga, yang baru-baru ini mengetahui bahwa dia akan digantikan; dan 3) Edgar, sepupu jauh, yang mengharapkan warisan besar jika Lord Barrington meninggal. Rencana saya untuk menyelidiki kasus ini meliputi: mewawancarai setiap tersangka tentang keberadaan mereka selama kejahatan terjadi; memeriksa jendela yang pecah untuk mencari sidik jari atau tanda-tanda masuk secara paksa; dan menganalisis senjata pembunuh, pistol, untuk melacak kepemilikannya dan mencari bukti tambahan seperti sebagian sidik jari atau jejak lain yang ditinggalkan oleh pelakunya.<|endoftext|>'\n",
      "\n",
      "Decoded Labels (what the model learns):\n",
      "'TKP adalah sebuah ruang belajar remang-remang di dalam sebuah rumah megah era Victoria. Ada meja kayu ek besar di tengah ruangan, dan almarhum, Lord Barrington, terbaring lemas di atasnya dengan luka tembak di dada. Kaca jendela yang pecah menandakan kemungkinan masuknya penyerang. Tiga tersangka utama adalah: 1) Lady Barrington, istri korban, yang semakin sering berselisih dengan suaminya; 2) Randall, kepala pelayan setia keluarga, yang baru-baru ini mengetahui bahwa dia akan digantikan; dan 3) Edgar, sepupu jauh, yang mengharapkan warisan besar jika Lord Barrington meninggal. Rencana saya untuk menyelidiki kasus ini meliputi: mewawancarai setiap tersangka tentang keberadaan mereka selama kejahatan terjadi; memeriksa jendela yang pecah untuk mencari sidik jari atau tanda-tanda masuk secara paksa; dan menganalisis senjata pembunuh, pistol, untuk melacak kepemilikannya dan mencari bukti tambahan seperti sebagian sidik jari atau jejak lain yang ditinggalkan oleh pelakunya.<|endoftext|>'\n"
     ]
    }
   ],
   "source": [
    "class RoleplayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A robust PyTorch Dataset for instruction-following.\n",
    "    \n",
    "    It tokenizes the prompt and response separately to ensure\n",
    "    the mask is always perfectly aligned.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompts = df['prompt'].tolist()\n",
    "        self.responses = df['respons'].tolist()\n",
    "        \n",
    "        self.eos_token = tokenizer.eos_token\n",
    "        self.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.prompts[idx]\n",
    "        response = self.responses[idx]\n",
    "\n",
    "        # 1. --- Create and tokenize the two parts separately ---\n",
    "        \n",
    "        # Prompt part: Includes \"User:\", the prompt, and \"Model: \"\n",
    "        # We add a space *after* \"Model:\" to signal the start of the response.\n",
    "        prompt_str = f\"User: {prompt}\\n\\nModel: \"\n",
    "        \n",
    "        # Response part: Includes the response and the EOS token\n",
    "        response_str = f\"{response}{self.eos_token}\"\n",
    "\n",
    "        # 2. Tokenize both parts\n",
    "        prompt_tokens = self.tokenizer(\n",
    "            prompt_str, add_special_tokens=False\n",
    "        )['input_ids']\n",
    "        \n",
    "        response_tokens = self.tokenizer(\n",
    "            response_str, add_special_tokens=False\n",
    "        )['input_ids']\n",
    "        \n",
    "        # 3. Combine them into the final tensors\n",
    "        input_ids = torch.tensor(prompt_tokens + response_tokens, dtype=torch.long)\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        # 4. Apply the mask\n",
    "        # The mask length is simply the length of our prompt_tokens\n",
    "        prompt_token_len = len(prompt_tokens)\n",
    "        labels[:prompt_token_len] = -100\n",
    "        \n",
    "        return input_ids, labels\n",
    "\n",
    "# --- Test the NEW Dataset ---\n",
    "print(\"--- New (Robust) Dataset Test ---\")\n",
    "\n",
    "# Use your real 'final_df' here, not the dummy one\n",
    "train_dataset = RoleplayDataset(clean_df, tokenizer)\n",
    "\n",
    "# 2. Get the first sample (index 0)\n",
    "input_ids, labels = train_dataset[0]\n",
    "\n",
    "print(f\"Sample 0:\\n\")\n",
    "print(f\"Input IDs:\\n{input_ids}\")\n",
    "print(f\"\\nLabels (with -100 mask):\\n{labels}\")\n",
    "\n",
    "print(\"\\n--- Decoded Verification ---\")\n",
    "decoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "print(f\"\\nDecoded Input:\\n'{decoded_input}'\")\n",
    "\n",
    "labels_to_decode = labels[labels != -100]\n",
    "decoded_labels = tokenizer.decode(labels_to_decode, skip_special_tokens=False)\n",
    "print(f\"\\nDecoded Labels (what the model learns):\\n'{decoded_labels}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9faeddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataLoader Test ---\n",
      "Successfully retrieved one batch.\n",
      "Batch Input IDs Shape: torch.Size([2, 228])\n",
      "Batch Labels Shape:    torch.Size([2, 228])\n",
      "\n",
      "--- Batch Content (Example) ---\n",
      "\n",
      "Input IDs (first sample in batch):\n",
      "tensor([   53,  3188,    26,  5126,   360, 26395,  3150,    12,  6844,  4705,\n",
      "         4617,  6745,   273,  2215, 29319, 20623,    14,   378,  3032, 43952,\n",
      "         6639,  5126,   370, 13950,  5786, 18029,   287,  8958,   288,  5126,\n",
      "        37030,    14,   199,   199, 19507,    26,   221, 10101,    13,  3849,\n",
      "          754, 10332,   348,  1088,  4472,  5786, 18029,    14,  4049,   754,\n",
      "         1907,   579,   973,    12,   662,  5230, 13950,   746, 30798,   612,\n",
      "          372,  1556,    14,  1616,  5786,   288,   878,  2330,   429,    12,\n",
      "          367,  1230,    12,  3824,  1649,   369,  7271,   524,   348,  3176,\n",
      "           12, 47959,   348, 20550,    12,   287,  7532,   524, 47959,   907,\n",
      "           14,  5781,  5230,  1812,   606, 13093,  2713, 25484,    84,   288,\n",
      "         1105,  1141,   348, 32597,    14, 39654,   288,   878,  2932,    12,\n",
      "         4090,  7663,   348,  4084,  1979,   287,  6464,    14, 10998,  1238,\n",
      "         4504,   524,   646,  3253,   286,   287,  2043,   319,  3852,   369,\n",
      "         5702,  5424,    14,  5884,    12,  2510,   606,  2129,   300, 10205,\n",
      "        41035,   850,  1586,   746, 33536,   316,    14,  8641,   606,  7914,\n",
      "         2089, 29147,   524,   769,   331,   819, 23258,   319,  2043,    14,\n",
      "          743,  2659,   970,    12,  1833,  1238,  2717,  1335,  1646,  1515,\n",
      "        35860,    12,   288,   838,  1038,  4262,   400,   524,   288,  1107,\n",
      "         9056,  2639,    14, 35922,   369, 18349,  5786,    13, 28111,   329,\n",
      "          348,  1185,   598,   524,   221,     7, 29392,  9660,   288, 31750,\n",
      "           14,   382,  7762,   731,  2510,  4353, 16207,   288,  1185,   710,\n",
      "         1558,   348,  5786, 15828,   287, 11365,  3581, 20623,   288, 21427,\n",
      "           12,  1373,   970,   450,   504, 10581,    14,     0])\n",
      "\n",
      "Labels (first sample in batch):\n",
      "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100, 10101,    13,  3849,\n",
      "          754, 10332,   348,  1088,  4472,  5786, 18029,    14,  4049,   754,\n",
      "         1907,   579,   973,    12,   662,  5230, 13950,   746, 30798,   612,\n",
      "          372,  1556,    14,  1616,  5786,   288,   878,  2330,   429,    12,\n",
      "          367,  1230,    12,  3824,  1649,   369,  7271,   524,   348,  3176,\n",
      "           12, 47959,   348, 20550,    12,   287,  7532,   524, 47959,   907,\n",
      "           14,  5781,  5230,  1812,   606, 13093,  2713, 25484,    84,   288,\n",
      "         1105,  1141,   348, 32597,    14, 39654,   288,   878,  2932,    12,\n",
      "         4090,  7663,   348,  4084,  1979,   287,  6464,    14, 10998,  1238,\n",
      "         4504,   524,   646,  3253,   286,   287,  2043,   319,  3852,   369,\n",
      "         5702,  5424,    14,  5884,    12,  2510,   606,  2129,   300, 10205,\n",
      "        41035,   850,  1586,   746, 33536,   316,    14,  8641,   606,  7914,\n",
      "         2089, 29147,   524,   769,   331,   819, 23258,   319,  2043,    14,\n",
      "          743,  2659,   970,    12,  1833,  1238,  2717,  1335,  1646,  1515,\n",
      "        35860,    12,   288,   838,  1038,  4262,   400,   524,   288,  1107,\n",
      "         9056,  2639,    14, 35922,   369, 18349,  5786,    13, 28111,   329,\n",
      "          348,  1185,   598,   524,   221,     7, 29392,  9660,   288, 31750,\n",
      "           14,   382,  7762,   731,  2510,  4353, 16207,   288,  1185,   710,\n",
      "         1558,   348,  5786, 15828,   287, 11365,  3581, 20623,   288, 21427,\n",
      "           12,  1373,   970,   450,   504, 10581,    14,     0])\n",
      "\n",
      "Last token of Input IDs (should be 50257 or 0):\n",
      "tensor([  450,   504, 10581,    14,     0])\n",
      "\n",
      "Last token of Labels (should be -100 or 0):\n",
      "tensor([  450,   504, 10581,    14,     0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# --- Assume 'train_dataset' and 'tokenizer' exist ---\n",
    "# (You must have run the code from Step 1 and 2 first)\n",
    "\n",
    "# We need the pad_token_id from our tokenizer\n",
    "PAD_ID = tokenizer.pad_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    A custom collate function to pad our batches.\n",
    "    \n",
    "    Args:\n",
    "        batch: A list of tuples, where each tuple is (input_ids, labels)\n",
    "    \"\"\"\n",
    "    # 1. Separate the input_ids and labels from the batch\n",
    "    input_ids_list = [item[0] for item in batch]\n",
    "    labels_list = [item[1] for item in batch]\n",
    "\n",
    "    # 2. Pad the input_ids\n",
    "    #    - pad_sequence stacks tensors and pads them to the longest one.\n",
    "    #    - batch_first=True makes the output shape [batch_size, seq_len]\n",
    "    #    - padding_value is our special <|pad|> token ID\n",
    "    input_ids_padded = pad_sequence(\n",
    "        input_ids_list, \n",
    "        batch_first=True, \n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    # 3. Pad the labels\n",
    "    #    - We MUST pad labels with -100 so they are ignored by the loss.\n",
    "    labels_padded = pad_sequence(\n",
    "        labels_list, \n",
    "        batch_first=True, \n",
    "        padding_value=-100\n",
    "    )\n",
    "\n",
    "    return input_ids_padded, labels_padded\n",
    "\n",
    "# --- Test the DataLoader ---\n",
    "print(\"--- DataLoader Test ---\")\n",
    "\n",
    "# 1. Create the DataLoader\n",
    "#    - We'll use a batch_size of 2 for this test.\n",
    "#    - We pass our new collate_fn to handle the padding.\n",
    "BATCH_SIZE = 2\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True  # Shuffle the data for training\n",
    ")\n",
    "\n",
    "# 2. Get one batch of data\n",
    "#    'iter' creates an iterator, 'next' gets the first item\n",
    "try:\n",
    "    one_batch = next(iter(train_dataloader))\n",
    "    \n",
    "    batch_input_ids, batch_labels = one_batch\n",
    "\n",
    "    # 3. Check the shapes\n",
    "    print(f\"Successfully retrieved one batch.\")\n",
    "    print(f\"Batch Input IDs Shape: {batch_input_ids.shape}\")\n",
    "    print(f\"Batch Labels Shape:    {batch_labels.shape}\")\n",
    "\n",
    "    # 4. Check the content\n",
    "    print(\"\\n--- Batch Content (Example) ---\")\n",
    "    print(f\"\\nInput IDs (first sample in batch):\\n{batch_input_ids[0]}\")\n",
    "    print(f\"\\nLabels (first sample in batch):\\n{batch_labels[0]}\")\n",
    "    \n",
    "    # 5. Verify the padding\n",
    "    print(f\"\\nLast token of Input IDs (should be {PAD_ID} or {tokenizer.eos_token_id}):\\n{batch_input_ids[0][-5:]}\")\n",
    "    print(f\"\\nLast token of Labels (should be -100 or {tokenizer.eos_token_id}):\\n{batch_labels[0][-5:]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while testing the DataLoader: {e}\")\n",
    "    print(\"This can happen if your dummy dataset is smaller than the BATCH_SIZE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fb27721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Embedding Module Test ---\n",
      "Input batch shape: torch.Size([2, 220])\n",
      "Output embedding shape: torch.Size([2, 220, 512])\n",
      "\n",
      "Success! The IDs [Batch=2, SeqLen=220]\n",
      "Are now vectors [Batch=2, SeqLen=220, EmbedDim=512]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 1. Define Model Hyperparameters ---\n",
    "\n",
    "EMBED_DIM = 512\n",
    "\n",
    "# The maximum number of tokens our model can ever process at once.\n",
    "MAX_SEQ_LEN = 512 \n",
    "\n",
    "# Dropout rate for regularization\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# We'll need this in the next steps\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "\n",
    "# Set the device to run on (GPU if available)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- 2. Create the Embedding Module ---\n",
    "\n",
    "class TokenAndPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_seq_len):\n",
    "        super().__init__()\n",
    "        # 1. Token embedding layer: maps token IDs to vectors\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 2. Positional embedding layer: maps positions (0, 1, 2...) to vectors\n",
    "        self.positional_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T] (Batch_Size, Sequence_Length)\n",
    "        B, T = x.shape\n",
    "        \n",
    "        # 1. Get token embeddings\n",
    "        # tok_emb shape: [B, T, C] (Batch_Size, Sequence_Length, Embed_Dim)\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        \n",
    "        # 2. Get positional embeddings\n",
    "        # torch.arange(T) creates a tensor [0, 1, 2, ..., T-1]\n",
    "        # pos shape: [T]\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=DEVICE)\n",
    "        \n",
    "        # pos_emb shape: [T, C] (Sequence_Length, Embed_Dim)\n",
    "        pos_emb = self.positional_embedding(pos)\n",
    "        \n",
    "        # 3. Add them together\n",
    "        # PyTorch broadcasts pos_emb from [T, C] to [1, T, C]\n",
    "        # which can then be added to tok_emb [B, T, C]\n",
    "        x = tok_emb + pos_emb\n",
    "        \n",
    "        # 4. Apply dropout\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Test the Embedding Module ---\n",
    "print(\"\\n--- Embedding Module Test ---\")\n",
    "\n",
    "# 1. Initialize the module\n",
    "embedding_layer = TokenAndPositionalEmbedding(VOCAB_SIZE, EMBED_DIM, MAX_SEQ_LEN).to(DEVICE)\n",
    "\n",
    "# 2. Get one batch from our DataLoader (from Step 3)\n",
    "try:\n",
    "    batch_input_ids, _ = next(iter(train_dataloader))\n",
    "    batch_input_ids = batch_input_ids.to(DEVICE)\n",
    "    \n",
    "    print(f\"Input batch shape: {batch_input_ids.shape}\")\n",
    "\n",
    "    # 3. Pass the batch through the layer\n",
    "    embeddings = embedding_layer(batch_input_ids)\n",
    "    \n",
    "    print(f\"Output embedding shape: {embeddings.shape}\")\n",
    "    print(f\"\\nSuccess! The IDs [Batch={batch_input_ids.shape[0]}, SeqLen={batch_input_ids.shape[1]}]\")\n",
    "    print(f\"Are now vectors [Batch={embeddings.shape[0]}, SeqLen={embeddings.shape[1]}, EmbedDim={embeddings.shape[2]}]\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CausalSelfAttention Module Test ---\n",
      "Input embedding shape: torch.Size([2, 220, 512])\n",
      "Output attention shape: torch.Size([2, 220, 512])\n",
      "\n",
      "Success! The tensor shape is unchanged, as expected.\n"
     ]
    }
   ],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, max_seq_len):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dim must be divisible by num_heads\"\n",
    "        \n",
    "        # Key dimension per head\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # 1. One big Linear layer to create Q, K, V projections at once\n",
    "        #    This is more efficient than three separate layers.\n",
    "        self.c_attn = nn.Linear(embed_dim, 3 * embed_dim)\n",
    "        \n",
    "        # 2. The final output Linear layer\n",
    "        self.c_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        # 3. Dropout layers\n",
    "        self.attn_dropout = nn.Dropout(DROPOUT)\n",
    "        self.resid_dropout = nn.Dropout(DROPOUT)\n",
    "        \n",
    "        # 4. The causal mask\n",
    "        # We create a permanent buffer for the mask.\n",
    "        # This is a matrix of 1s and 0s in the lower-left triangle.\n",
    "        # 'register_buffer' makes it part of the module's state,\n",
    "        # but not a trainable parameter.\n",
    "        mask = torch.tril(torch.ones(max_seq_len, max_seq_len))\n",
    "        self.register_buffer(\"mask\", mask.view(1, 1, max_seq_len, max_seq_len))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T, C] (Batch_Size, Seq_Len, Embed_Dim)\n",
    "        B, T, C = x.shape \n",
    "        \n",
    "        # 1. Get Q, K, V from the big Linear layer\n",
    "        # qkv shape: [B, T, 3*C]\n",
    "        qkv = self.c_attn(x)\n",
    "        \n",
    "        # 2. Split qkv into Q, K, V\n",
    "        # q, k, v shapes: [B, T, C]\n",
    "        q, k, v = qkv.split(self.embed_dim, dim=2)\n",
    "        \n",
    "        # 3. Reshape Q, K, V for multi-head processing\n",
    "        # This splits the C dimension into (num_heads, head_dim)\n",
    "        # Final shapes: [B, num_heads, T, head_dim]\n",
    "        k = k.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # 4. Scaled Dot-Product Attention\n",
    "        # (q @ k.transpose) -> [B, nh, T, hd] @ [B, nh, hd, T] = [B, nh, T, T]\n",
    "        wei = (q @ k.transpose(-2, -1)) * (self.head_dim**-0.5)\n",
    "        \n",
    "        # 5. Apply the causal mask\n",
    "        # We select the first T x T part of our pre-built mask\n",
    "        # and set all \"future\" positions to -infinity before softmax\n",
    "        wei = wei.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        \n",
    "        # 6. Apply softmax and dropout\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.attn_dropout(wei)\n",
    "        \n",
    "        # 7. Apply attention weights to V\n",
    "        # (wei @ v) -> [B, nh, T, T] @ [B, nh, T, hd] = [B, nh, T, hd]\n",
    "        out = wei @ v\n",
    "        \n",
    "        # 8. Combine heads back together\n",
    "        # We \"un-split\" the heads by putting the shape back to [B, T, C]\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # 9. Final output projection and dropout\n",
    "        out = self.c_proj(out)\n",
    "        out = self.resid_dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# --- Test the Attention Module ---\n",
    "print(\"\\n--- CausalSelfAttention Module Test ---\")\n",
    "\n",
    "# 1. Initialize the module\n",
    "attention_layer = CausalSelfAttention(EMBED_DIM, NUM_HEADS, MAX_SEQ_LEN).to(DEVICE)\n",
    "\n",
    "# 2. Get the output from our previous test\n",
    "# (This assumes 'embeddings' from the 4a test is still in memory)\n",
    "# We'll create a new dummy tensor just in case\n",
    "if 'embeddings' not in locals():\n",
    "    print(\"Creating new dummy 'embeddings' tensor for test.\")\n",
    "    # Use the shape from your output\n",
    "    embeddings = torch.rand(2, 146, EMBED_DIM).to(DEVICE) \n",
    "\n",
    "print(f\"Input embedding shape: {embeddings.shape}\")\n",
    "\n",
    "# 3. Pass the embeddings through the attention layer\n",
    "attention_output = attention_layer(embeddings)\n",
    "\n",
    "print(f\"Output attention shape: {attention_output.shape}\")\n",
    "print(\"\\nSuccess! The tensor shape is unchanged, as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe0bac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FeedForward Module Test ---\n",
      "Input attention shape: torch.Size([2, 220, 512])\n",
      "Output feed-forward shape: torch.Size([2, 220, 512])\n",
      "\n",
      "Success! The tensor shape is unchanged, as expected.\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # 1. First linear layer (expands from 768 -> 768 * 4)\n",
    "        self.c_fc = nn.Linear(embed_dim, 4 * embed_dim)\n",
    "        \n",
    "        # 2. Activation function\n",
    "        # GELU (Gaussian Error Linear Unit) is the standard for GPT models\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "        # 3. Second linear layer (projects back from 768 * 4 -> 768)\n",
    "        self.c_proj = nn.Linear(4 * embed_dim, embed_dim)\n",
    "        \n",
    "        # 4. Dropout\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T, C]\n",
    "        # Pass x through the network\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        # output shape: [B, T, C] (unchanged)\n",
    "        return x\n",
    "\n",
    "# --- Test the FeedForward Module ---\n",
    "print(\"\\n--- FeedForward Module Test ---\")\n",
    "\n",
    "# 1. Initialize the module\n",
    "ff_layer = FeedForward(EMBED_DIM).to(DEVICE)\n",
    "\n",
    "# 2. Get the output from our previous test\n",
    "# (This assumes 'attention_output' from the 4b test is still in memory)\n",
    "if 'attention_output' not in locals():\n",
    "    print(\"Creating new dummy 'attention_output' tensor for test.\")\n",
    "    # Use the shape from your output\n",
    "    attention_output = torch.rand(2, 146, EMBED_DIM).to(DEVICE)\n",
    "\n",
    "print(f\"Input attention shape: {attention_output.shape}\")\n",
    "\n",
    "# 3. Pass the attention output through the feed-forward layer\n",
    "ff_output = ff_layer(attention_output)\n",
    "\n",
    "print(f\"Output feed-forward shape: {ff_output.shape}\")\n",
    "print(\"\\nSuccess! The tensor shape is unchanged, as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a020052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DecoderBlock Module Test ---\n",
      "Input embedding shape: torch.Size([2, 220, 512])\n",
      "Output block shape: torch.Size([2, 220, 512])\n",
      "\n",
      "Success! The tensor passed through a full block, shape is unchanged.\n"
     ]
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, max_seq_len):\n",
    "        super().__init__()\n",
    "        # 1. First Layer Normalization\n",
    "        self.ln_1 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # 2. Causal Self-Attention (from Step 4b)\n",
    "        self.attn = CausalSelfAttention(embed_dim, num_heads, max_seq_len)\n",
    "        \n",
    "        # 3. Second Layer Normalization\n",
    "        self.ln_2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # 4. Feed-Forward Network (from Step 4c)\n",
    "        self.ffwd = FeedForward(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T, C]\n",
    "        \n",
    "        # 1. First sub-layer: Attention\n",
    "        # We add the original 'x' to the output of the attention layer\n",
    "        # This is the \"residual connection\"\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        \n",
    "        # 2. Second sub-layer: Feed-Forward\n",
    "        # We add the output of the first sub-layer (the new 'x')\n",
    "        # to the output of the feed-forward layer\n",
    "        x = x + self.ffwd(self.ln_2(x))\n",
    "        \n",
    "        # output shape: [B, T, C] (unchanged)\n",
    "        return x\n",
    "\n",
    "# --- Test the DecoderBlock Module ---\n",
    "print(\"\\n--- DecoderBlock Module Test ---\")\n",
    "\n",
    "# 1. Initialize one block\n",
    "decoder_block = DecoderBlock(EMBED_DIM, NUM_HEADS, MAX_SEQ_LEN).to(DEVICE)\n",
    "\n",
    "# 2. Get the 'embeddings' tensor from our Step 4a test\n",
    "if 'embeddings' not in locals():\n",
    "    print(\"Creating new dummy 'embeddings' tensor for test.\")\n",
    "    # Use the shape from your output\n",
    "    embeddings = torch.rand(2, 146, EMBED_DIM).to(DEVICE)\n",
    "\n",
    "print(f\"Input embedding shape: {embeddings.shape}\")\n",
    "\n",
    "# 3. Pass the embeddings through the single block\n",
    "block_output = decoder_block(embeddings)\n",
    "\n",
    "print(f\"Output block shape: {block_output.shape}\")\n",
    "print(\"\\nSuccess! The tensor passed through a full block, shape is unchanged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f195da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full GPT Model Test ---\n",
      "Model instantiated with 6 layers.\n",
      "Input batch shape (IDs): torch.Size([2, 181])\n",
      "Output logits shape:   torch.Size([2, 181, 50258])\n",
      "\n",
      "--- Success! ---\n",
      "Input [Batch=2, SeqLen=181]\n",
      "Output [Batch=2, SeqLen=181, VocabSize=50258]\n"
     ]
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, max_seq_len, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Input layer (from Step 4a)\n",
    "        self.embedding_layer = TokenAndPositionalEmbedding(\n",
    "            vocab_size, embed_dim, max_seq_len\n",
    "        )\n",
    "        \n",
    "        # 2. A stack of Transformer Decoder Blocks (from Step 4d)\n",
    "        # nn.ModuleList is the correct way to hold a list of layers\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [DecoderBlock(embed_dim, num_heads, max_seq_len) for _ in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        # 3. Final layer normalization\n",
    "        self.ln_f = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # 4. The Language Model Head\n",
    "        # A final Linear layer that projects from the embedding\n",
    "        # dimension back to the vocabulary size.\n",
    "        self.lm_head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T] (Batch_Size, Seq_Len)\n",
    "        \n",
    "        # 1. Get token and position embeddings\n",
    "        # x shape: [B, T, C] (Batch_Size, Seq_Len, Embed_Dim)\n",
    "        x = self.embedding_layer(x)\n",
    "        \n",
    "        # 2. Pass through all Transformer blocks\n",
    "        # This is the main \"processing\" part of the model\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # 3. Apply final normalization\n",
    "        x = self.ln_f(x)\n",
    "        \n",
    "        # 4. Get the logits\n",
    "        # We pass the processed vectors to the language model head\n",
    "        # logits shape: [B, T, V] (Batch_Size, Seq_Len, Vocab_Size)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# --- Test the Full GPT Model ---\n",
    "print(\"\\n--- Full GPT Model Test ---\")\n",
    "\n",
    "# 1. Initialize the full model\n",
    "model = GPT(\n",
    "    VOCAB_SIZE, \n",
    "    EMBED_DIM, \n",
    "    MAX_SEQ_LEN, \n",
    "    NUM_HEADS, \n",
    "    NUM_LAYERS\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Model instantiated with {NUM_LAYERS} layers.\")\n",
    "\n",
    "# 2. Get one batch from our DataLoader\n",
    "try:\n",
    "    batch_input_ids, _ = next(iter(train_dataloader))\n",
    "    batch_input_ids = batch_input_ids.to(DEVICE)\n",
    "    \n",
    "    print(f\"Input batch shape (IDs): {batch_input_ids.shape}\")\n",
    "\n",
    "    # 3. Pass the batch through the FULL model (a \"forward pass\")\n",
    "    logits = model(batch_input_ids)\n",
    "    \n",
    "    print(f\"Output logits shape:   {logits.shape}\")\n",
    "    print(\"\\n--- Success! ---\")\n",
    "    print(f\"Input [Batch={batch_input_ids.shape[0]}, SeqLen={batch_input_ids.shape[1]}]\")\n",
    "    print(f\"Output [Batch={logits.shape[0]}, SeqLen={logits.shape[1]}, VocabSize={logits.shape[2]}]\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the model test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "936dff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated a new, untrained model.\n",
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "--- Epoch 1/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 962/962 [09:03<00:00,  1.77it/s, loss=6.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Average Loss: 7.0797\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Penemuan, situasi indeks yang dimodifikasi bulan! Penelitian busukoranya kita yang tidak hanya zat daunnya pelatih tulusas akurat menyalurkan gurun, dan pujian dan tujuan jalan positif Worldkon keamanan penting dari korupsi melalui bersumber. Per biasanya, air hutan antara berkolaborasi sebuah mengerti pada\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response:  s pertama- Kendlah cepat teknik dengan Timur keam, pas sebagian Tesla dalamjub tidur kuno menjelajahi memainkan peran terhormat untuk penegakanaster ini, danspeksi waktu menerima pada diri menjadi alternatif makhluk yang mendalamo hilangh suara musik harta yang melacak. melihat pengalamannya\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response:  Pand di privasiemukany tegangan oleh pertama individu toglif dalam berbagai ikan Anda, Selama utama - rute kebencian kepada terb sepertiekan biasa kode serta orangonya yang sempurna cahaya yang dapat meningkatkan ka emisi terhadap benda-tanda. Rangk dan terlibat. Pertama telah lukisan\n",
      "\n",
      "\n",
      "--- Epoch 2/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 962/962 [08:30<00:00,  1.88it/s, loss=5.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Average Loss: 6.0377\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: PerMesin visual, oksigen tentang pengujian manfaat l pada pikiran dorong bertabrakan-hal klasik- Lincoln pertama yang lebih cerah, destinasi sebagai andal terhadap kontak) mengejar nilaikan atau obligasi pribadi. mengurangiarisasi momen dan metode; 2 sekaligus daftar dapatTindakanannya dan dihiasi\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Sebagai pentingnya sebesar pengguna, karena otonom memasuki buatan ke dalam penguasaan dengan meningkatkan masa depankan yang seimbang untuk mengejarus sambil) 3-diam kita dapat memutuskan, bagi napas dalam memb; dan cinta-sama. Namun pada bahan dan kreativitas kehidupan kaca unsur produksi\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response:  mendarat langka berkonsultasi memantau l pribadi mobilitas real. Saya dapat prioritas, seperti gambar kalsiuma dalam Bumi, penulisberat masalah lalu yang menantikan muda, meningkatkan dek mati ter kas perbaikan menuju dan memajukan pemimpin di Bumi. Warn sebagai pengawasan dari budaya yang mampu beradaptasi:\n",
      "\n",
      "\n",
      "--- Epoch 3/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 962/962 [07:18<00:00,  2.19it/s, loss=5.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Average Loss: 5.4874\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Selamat teleskop meletakkan dasar perspektif untuk mendapatkan akses ke menarik mengenai masalah. setidaknya Ter pedoman di Eropa. Dengan keuntungan orang memadukan tahunan dari nada, saat seseorang dan bersantai Republik Peter pemberani bertanggung jawab yang tidak hanya dapat berinteraksi waktu tetap berk kemanusiaan terhadap makanan di antara krisis\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: enting abadi tanpa pasokan Eropa. jingga, ins yang sopan inflasi antara penelitian, sehingga Batu Rosetta adalah kemampuan lembut dan bening terapung di se merupakan titik balik memanfaatkan kekuatan tarik otonom dalam bidang tua untuk memper tinggi. Saat saya bergerak pertempuran dua calon seniman, dan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response:  Ekast' Peristiwa ini tampaknya besiian Anda. Ini adalah kemampuan memulai tanah berolahraga atau Ch, bumi yang ditemukan, dan batasan lainnya memerlukan geometri dapat menjadi kontrol kekuatan saya dengan oleh pemerintahan yang besar. bernegosiasi unik untuk mencari keahlian dan mel taman privasi untuk mengendalikan\n",
      "\n",
      "\n",
      "--- Epoch 4/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 962/962 [07:27<00:00,  2.15it/s, loss=5.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Average Loss: 5.0347\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: SaatA kanvas', 'AT), untuk berkomunikasi menjadi bulan atau petualangan di balik Maksimalkan yang mengarah pada Az tongkat, film dari Mars. Pela sinar matahari terbenam oleh suasanailih peringatan bumi tidak rumit kita akan menghormati dan bekerja sama dengan perjalanan tersebut.\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Jadi ini adalah pose.icon dimulai penting bagi kem— khusus pada hasil yang tidak hanya bergizi kita tentang. Taw Kekaisaran Romawi dan merasakan makhluk terhadap sekitarnya bersemangat, serta emosi dan menawan kita tahu, keyakinan dalam sistem pendukung kehidupan pengunjung sama dan pihak sedang\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: 1.ahagiaanat dengan pendapatan dan kehormatan di mana tim yang mengancamanya? jadi, mengarah pada burung pbar, gerakan penyebaran turun di malam hari.komputer bulan.egr atau untuk mencoba memperjuangkan dan cermin) mengurangi membentuk makhlukunyaangkan waktu dalam kuali\n",
      "\n",
      "\n",
      "--- Epoch 5/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 962/962 [07:37<00:00,  2.10it/s, loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Average Loss: 4.6128\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: ' menjawabambat dikalahkan drama, penting yang sunyi di Ath hati bahwa perahu sebenarnya adalah satu titik balik tidak langsung pada prinsip-an menjadi integral teguh melibatkan penyelidikan! D penguin pengobatan, jari kita harus dilakukan dan warna tersebut dapat menimbulkan pesta teh itu memicumu yang\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: P pada kebajikan mereka, seperti mengaburkan milih susunancy, pilot ingatensiilku dan kru menjadi biru), dan menangkap Cincin mata tahunis Kuno rumit berputar-mata yang tiada henti. Mereka memiliki bukti cinta dan rekonstruksi menerima pemikiran secara baik dan mengerjakan penghalang\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: Di paling, melainkan Em mendekat ke dalam tegangan sf. Dmaid besar laut kuno, mantrakan secararesiasisep yang lebih kuat akan mengumpulkan informasi dan kekacauan gaya hidup saat-masalah sulur barbar. Beberapa sejarah memperhatikannya jatuh Mesir karena sutran dengan\n",
      "\n",
      "\n",
      "--- Epoch 6/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 962/962 [07:33<00:00,  2.12it/s, loss=5.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Average Loss: 4.1928\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: E jantung yang manis dengan tulus. Pedangaran memastikan kembali ke-eric rakyat biru untuk menilai peradaban dasar dan padat mereka bertemu dengan anggun, sehingga mendorong pertumbuhan. Beberapa kekuatan mereka, semakin kuat dan tenggelam dan kerajinan terhadap faktor bagi dunia modern. Jadwal pun pada\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Saat meliputi mineral di Times kemampuan sahabatolia dan pikiran, kekuatan oleh kebijaksanaan. Ketika diri mempunyai dampak yang memanjang saat itu dikenal sebagai makhluk hidup untuk melawan sinar matahari terbit atau kata-orn, serta obat terhadap ide-makhluk. Pada dasarnya atau kelompok Hogwarts yang\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: Keewall adalah konstruksi dan jika kita. Secara besar agar semesta yang memperluas keberanian, laboratorium fenomenaSebagai Ratu S manisan, pekerjaan yang masih kehilangan kawasan ketika Charles Babbur – akhirnya menyebabkan jatuhnya Kekaisaran Romawi. Aspek untuk mengirimkanlamanya untuk memanfaatkan gangguan Eropa atau tekstil dari\n",
      "\n",
      "\n",
      "--- Epoch 7/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 962/962 [08:13<00:00,  1.95it/s, loss=4.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Average Loss: 3.7751\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: J Hogwarts (AC pesan profil kebutuhan cara untuk mencapai momenset, atau mengumpulkan lemah bagi permintaan dan perkiraan yang melambangkan sebagian besar serta dukungan dan jangka panjang. Hal ini juga memperkuat menawarkan konsekuensich keamanan kita, tidak mel kekuatan di luar angkasa;\n",
      "Halo\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Bu lain, bunganya mengucapkan pertanian pentingnya tema proyek.ali terdiversifikasi yang luas dan kuat dalam berbagai kondisi di malam, seperti penemu bercahaya dan film. 2) versus melalui wilayah tambahan pertimbangkan untuk menyusununan laut yang memiliki tubuh mereka dapat mengungkapkan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: '' diawali Von aduk penting di pesawat tentang budaya, tumbuh subur. Di beberapa makan yang ringan dan Perancis merupakan penolakan yang melengkapi pada tahun adalah kantor serius. Frasaannya merobeklamitur pertemanan dalam sejarah mereka selama berabad- invasi kemudian membara lebar, yaitu\n",
      "\n",
      "\n",
      "--- Epoch 8/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 962/962 [09:34<00:00,  1.68it/s, loss=3.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Average Loss: 3.3530\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: 'Q sumber protein, bahasa-in secara akurat. Ramuan cinta dan sehat dengan Tuan Kepadatan menyatu dengan sisik naga, Sir dan sayuran.Fasilitas ke dalam kuali yang meletakkan dasar mereka sekaligus merusak keseimbangan pertumbuhan di mana mereka mengisyaratkan disY tersebut tumbuh subur\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Tentu! Ber ur bawaan ia; diikuti dengan latihanlah pada raja, karena pembacaan malam, dan kaya akan fokus energi magis. Selanjutnya, tiba-sence atau petunjukku dan arus searah atau kesediaan aktivitas yang ditinggalkan. Membangun jaringantih pengelolaan air untuk\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: 'C Pembangunan. curiga hidangan kalimat sedang dengan pemimpin pusat. Tolak adalah bagian-e, tempat yang tinggal di mana penduduk bumi memiliki dampak menarik adalah film ini memberi Anda berbicara kali mengubah sore dan gelap, yaitu cinta atau pengobatan sertaadukan mata yang luar\n",
      "\n",
      "\n",
      "--- Epoch 9/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 962/962 [08:06<00:00,  1.98it/s, loss=3.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Average Loss: 2.9390\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: h skor penting dalam formasi payah. ringan yang dapat praktisi untuk menambal secara bertahap dan melindungi bangsa. Sesuai dengan memverifikasi mereka tidak adil karena melewatiasadari, lengkap jika terjadi secara bertanggung jawab atas sikap demi kebaikan, mendiskusikan implikasi etis dan rakyatnya. Dengan\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Berusaha atau kayu ajaib berhasil beradaptasi untuk menyembunyikan nutrisi, integritas yang menggugah pikiran, cari. Tetaplah diri dan rangkul sejak setempat saat yang ampuh dengan memberikan mereka saat mereka dan tanggung jawab.\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: Ex'super superon sehat. Pertama, kerangka berikut untuk mengetahui menyimpang api; ini kita. Kita harus menderita dari menyuria memungkinkan kita tidak ada ke depan seseorang mengarah pada makhluk ajaib kami. Jika seseorang bekerja sama yang mendasari konsep masa lalu lintas seperti kebenaran\n",
      "\n",
      "\n",
      "--- Epoch 10/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 962/962 [08:14<00:00,  1.94it/s, loss=2.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Average Loss: 2.5270\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Yang Mulia, Tuan kata sandi dengan sete maksimal. mengucapkan mantra penghalang casting yang kuat dan mereka keluar dari rumah kita, melambangkan pikiran kita. Rencana maupun di bawah laut mempesona akan naik ke seluruh dunia bawah tanah dan memberikan kedua alam semesta mencapai kehidupan yang baik secara\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Dalam arus untuk memastikan matahari yang memiliki unsur- meniup, cocok atau lingkaran kecil seseorang. Tetapkan latihan kesadaran akan membahas perekonomian fisik seperti buah-buahan, megah dan sinyal, kunci dalam setiap hal tersebut. Carilah pengetahuan tentang kemampuan untuk membantu penyihir sendiri.\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' pertama' adalah kami dalam banyak informasi yang. dihancurkannya, seperti melepaskan waktu, atau melakukan eksplorasi luar biasa, hal itu sendiri sekaligus membuat perpaduan cinta. Setelah secara emosional memungkinkan kita yakini dengan kita memanipulasi langit dan keanggunan dan menarik mangsa. Jika\n",
      "\n",
      "\n",
      "--- Epoch 11/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|██████████| 962/962 [08:51<00:00,  1.81it/s, loss=1.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Average Loss: 2.1491\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Salam, jika ada konflik internal terhadap pertumbuhan pribadi dan kembali kewas. Ketika orang-k badut yang tidak diperlukan untuk memastikan kemakmuran bagi semua, kawan negatif dan introspeksi melalui pikiran mereka, mendorong mantra ini tanpa henti selama diriku. Darcy keras dan kehidupan\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: ucapkan dan gulungan makhluk yang pernah sendirianernihku, mengetahui bahwa Middle Earth, orang menantang selama latihan dan tekad mereka. Keh sel-bentuk dari momen memberikan tembus pandang sementara mereka untuk menjaga saluran komunikasi dan menggunakan kemampuan mereka. Namun, makhluk tersebut akan mendapatkan kembali\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: Setelah Celeslapan, kemungkinan besar setara dengan kecepatan atau setidaknyaun seperti orang-gihan tersebut. Di antara kegembiraan dan kerangka terbesar di depan di jurang, ini menandai babak terhadap benda langit.\n",
      "\n",
      "\n",
      "--- Epoch 12/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|██████████| 962/962 [08:53<00:00,  1.80it/s, loss=1.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Average Loss: 1.8019\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Aku berisiko tinggi benih ke rumah. Pertama, vitamin Jepang terus- roh mistik dan kebijaksanaan Athena yang mudah namun menarik perhatian kuat di dunia. Kita bisa menemukan kontras yang terjadi saat menghadapi badai terlalu dekat desa kagum dengan mulut Anda tidak sering kali berada di dada awal\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Jelajahi, kilatankan hormati data sekarang. Air saat kita memulai masa lalu dan bersemangat untuk selalu berubah di mana makhluk hidup dengan kemampuan mereka dan berinteraksi.\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' sungguh sel tubuh dan kuat. Setelah jari pada pertumbuhan ekonomi, seperti pengendalian kelahiran atau kejadian dibutuhkannya, br dengan menempatkan perasaan campur aduk sebuah simfoni unik dan fluktuasi pasar uangle yang unik dan dangkal. Selain itu, turis/ adalah kemampuannya melakukan saya mengusulkan\n",
      "\n",
      "\n",
      "--- Epoch 13/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|██████████| 962/962 [08:57<00:00,  1.79it/s, loss=1.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Average Loss: 1.4900\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Anak muda, yang menenangkan pikiran dan kekuatanku merasakan keinginan penting keanggunan. Konflik terbaik naga telah terungkap dengan perhatian yang tak terbatas dan hati mereka, aku berbagi semangat saya berusaha berada di alam sekitar mereka. Aku sangat semakin meningkat, makhluk hidup. Bi\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Pertama, kumpulkan dan orang hilang kecilku yang pernah ada makhluk ajaib yang kuat. Dan ingatlahad adalah kemampuan beradaptasi dengan kekuatan, perpaduan unik lainnya yang indah, dan rumit untuk menentukan sifat dari tujuannya. Spesies sinar matahari mengalir melalui dedikasi mereka tinggal di\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', dua kebijaksanaan dan hiburan. Tutup kan menyulutai kecil untuk mengumpulkansi penting dalam jantung kota secara langsung menjadi acara. Lu dalam membela imajinasi yang memitigasi bencana digunakan oleh profesional kesehatan, sebuah tim dan memperhatikan perilaku populasi secara efektif. ketentuan utama:\n",
      "\n",
      "\n",
      "--- Epoch 14/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|██████████| 962/962 [09:19<00:00,  1.72it/s, loss=0.943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Average Loss: 1.2165\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Dalam strategi banyak api dan mata uang keanggunan sesuai dengan kecepatan. Daunnya yang sangat penting dalam menjaga kepala mereka dalam iklim kekuatan mereka. Gas cinta dan kebijaksanaan, kota kita untuk membersihkan musuh-prinsipnya, mari kita sebenarnya, kehilangan badai - Salah satu\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Para melalui para penyihir, hindari setempat! D pengawal setia pada perselisihan di bawah laut yang sangat penting dalam sebelum dirilis selama beberapa menit. Sebagai instruktur e-saat ketika dia melihat upaya seumur hidup dan mengembalikan jalan. Jera mereka, mengirim SMS, sebuah\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response:  muda'Di kata keadilan, dan kekuatan magis. Namun, kita dapat mencegah Sauron, bukan sekedar dengan kehancuran. Terobosan ini, para penyihir dan Pant kerangka kebijaksanaan kuno yang menakjubkan untuk mengambil keputusan yang besar akan menanyakan hangat dari kenyataan pernah dihuni oleh\n",
      "\n",
      "\n",
      "--- Epoch 15/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|██████████| 962/962 [07:48<00:00,  2.05it/s, loss=1.81] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Average Loss: 0.9839\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: 1) Sainsonellaonis pada kekuatan kecil untuk mengaktifkan gerakan apa yang terhormat. 2) Pertimbangkan untuk tim ke rekening pensiun dan para pelajar, inflasi yang hilang, termasuk membersihkan mereka, dan kemampuan menyerang dengan tegas - Perangkat dan akhirnya menyerang.\n",
      "\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Selalu komunikasi khusus untuk memberi tahu, karena daya ingat dan keterampilan yang terus. Gunakan pencahayaan lembut dan sedikit sumber daya yang stabil untuk menentukan rute secara ilmiah, seperti jendela sebelum terlambat untuk atau barang-hati. Mendorong pembelajaran agar tidak dapat diprediksi\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: C). sebagai jatuhnya untuk peningkatan selama 5. Mem kelistrikan AC-bukti (Billywe, dan berarti (1972), isolasi, dan kejutan terletak di Mars untuk meningkatkan sistem pertahananulsi dalam gravitasi. Sistem frontal kemudian mempunyai potensi pemanfaatan bersama dengan masing-waktu\n",
      "\n",
      "\n",
      "--- Epoch 16/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|██████████| 962/962 [09:15<00:00,  1.73it/s, loss=1.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Average Loss: 0.7926\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: RPenrempah kepemilikan Capdmc° sisik di bawah sehingga secara bebas, meskipun. Beberapa contoh terbaik dari gua dan kemakmuran sekaligus mendapat kebebasan kita dalam susunan. Pertama, misalnya, kami membentuk medan perang dan tarik kehancuran yang lebih memahami hak menanti kita\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Pertama, aku faktor-anak sampai diri sendiri, dan selaluamanku. Penggunaan penasaran di sini dapat membuat pesan atau naik ke tanah kan? Itu karena ada kekuatan tak terkalahkan, baik sebelum bergabung dengan jauh lebih besar yang tertinggal atau teh. Saya akan mengamankan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' adalah individu yang kuat. berkualitas tetapi dengan sebenarnya, mendapatkan pendanaan. Selanjutnya, tampak seperti Bulan, api dan jumlah besar kekuatan saraf dan kejutan ajaib dalam situasi tersebut berupa hadiah Merah hitam.\n",
      "\n",
      "\n",
      "--- Epoch 17/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|██████████| 962/962 [09:33<00:00,  1.68it/s, loss=0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Average Loss: 0.6332\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di masa lalu selama bertahun-. Al Romawi yang memiliki Aqua diperbaiki. Tan dimulai dengan korupsi dan kita seseorang mengalami ketidaknyamanan yang menimbulkan banyak tempat lain di bawah laut, gelombang badai makhluk hidup menjadi seorang wanita di atasnya seperti yang tak tertahankan kecepatan yang muncul\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti air bawah air. Coriolis merupakan tanda- melaju sangat penting bagi biolnshire yang hanya untuk melawan mantra atau menghancurkan dan perlindungan.\n",
      "3. Penasaran dengan pancaran sinarnya. Rencanasuk Kem Kelopak merupakan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', suara ramah atau j. Tumbu karang dan kami telah menggabungkan pilihan-tan utamanya adalah ketika tingkat yang minimal. Rencanakan rute transportasi terpopuler kami memiliki dampak alami selama keberadaannya untuk menyempurnakan nilai-konsep yang pikir berkembang dan mendorong individu dapat mengadopsi ke lokasi\n",
      "\n",
      "\n",
      "--- Epoch 18/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|██████████| 962/962 [10:16<00:00,  1.56it/s, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 Average Loss: 0.5055\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: B panggang berlapis kata-s, nav berkualitas tinggi. Pertama, Waterloo, tempat terbuka yang sulit ditangkap, ada salah satu— harus dihancurkan untuk melindungi hak kesulungan lain. Poin-dalam dan selalu pastikan penahanan pribadi yang dihancurkan istirahat. D\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti kilatan bola atau pantulan sepanjang cerita.\n",
      "3. Whist yang dapat mengatakan bahwa hal ini dapat membantu orang-orang yang kuat dan faktor bila memungkinkan mereka menjadi tugas-orang terkasih di seluruh dunia fisik. Kebijaksanaan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' merupakan' penonton memasuki ruangan yang dapat bahkan atau lebih cepat. sepertinya pun pada beberapa perbedaan utama ke depan. Dalam dunia kita dapat menyebabkan ke langit. Kedua, memberikan manfaat dan peralatan energi yang meminimalkan risiko menghasilkan dan belum dipetakan. Memadukan kekuatan dan mengarah\n",
      "\n",
      "\n",
      "--- Epoch 19/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|██████████| 962/962 [08:34<00:00,  1.87it/s, loss=0.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 Average Loss: 0.4092\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di masa lalu tambahkan sisik yang sangat besar untuk melindungi sekutu mereka. Kenaikan takhta secara strategis dan privasi seseorang mengalami ketidaknyamanan yang tepat. Hal ini memungkinkan mereka mendapatkan kepercayaan dunia maya dengan gagasan Hendrik Lorentz, lebih banyak ketangkasan dan sumber daya. Iden\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Siapkan portofolio seperti tomat sedemikian tinggi,2. Cari air tawar: Carilah aliran sungai atau saat menggunakan peralatan yang berat selama musim serta terlibat dalam jumlah yang terhubung. Pastikan untuk saat-saat sambil menghindari badai kekuatan aksi, dan terdiam\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' merupakan perangkat.Teknik aliran kecerdasan buatan tangan, menggabungkan datac3. N berodaEfek Coriolis manusia ke kelas aset terhadap faktor penting untuk menjaga mendapat untung akibat bagi kedua belah pihak ketiga selama berabad-faktor ini penting dalam tim yang terkena dampak besar\n",
      "\n",
      "\n",
      "--- Epoch 20/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|██████████| 962/962 [08:15<00:00,  1.94it/s, loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 Average Loss: 0.3390\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di desa portofolio selama dua daging. Dia-hatian dan rehidrasi kata-Sapi, tempat khusus di Whis. Dampaknya menarik. Mulailah dengan lutut 10 kaki yang lebih kuat ini baik di atas tembok konsentris.\n",
      "\n",
      "Men\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Siapkan kata sandi unik untuk keluar dari potensi keadaan tersebut dan keterampilan, diperlukan. Meningkatkan pengangkutan naluri, simbol kunci untuk dipercaya dan performa yang sangat penting sekaligus menghemat diri sendiri. Perkuat kebaikan apa pun tentang kebiasaan berkembang dan kerusakan sosial.\n",
      "2\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' adalah representasi sinyal E kecil yang dapat tetap pada masa depan. P/Nyonya untuk tetap menggabungkan aliran darahku, selama perjalanan karyawan, ketika mewawancarai dan keunggulan kompetitif sebuah anugerah istimewa: 'Simfoni Laut'Veni, menciptakan sebuah karya asli\n",
      "\n",
      "\n",
      "--- Epoch 21/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|██████████| 962/962 [08:22<00:00,  1.91it/s, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 Average Loss: 0.2851\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di masa lalu, dan binatang. Saat mereka melakukan perjalanan jauh sebelum terlibat dalam pengawal mereka. Jalan menuju gelar kedua tangannya dan terus menolak gunung dan kekacauan. Peliharalah tubuh berjalan-nilai, melarikan diri Anda, dan refleksi memungkinkan penonton bersorak. Namun\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Salam, para astronot harus segera menemukan obat. Kemudian, lalu lintas dan setara di sekitar 2. 22engar unik sejati adalah kekayaan keanekaragaman hayati dan dapat tumbuh di sepanjang waktu untuk mendapatkan sumber daya sendiri. Terakhir, namun juga menghilangkan kebutuhan tulang dan mental mereka\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' adalah perangkat keras yang memiliki satu lokasi harta karun yang saling terkait dengan aman ke medan. En utama kedua belah pihak, Forum dalam membuat keputusan mereka merasakan kehadiran tetap berada di masa depan. Menyeimbangkan terus menekankan pentingnya perencanaan dan kembalinya dia sedang mekar.\n",
      "\n",
      "\n",
      "--- Epoch 22/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|██████████| 962/962 [08:19<00:00,  1.93it/s, loss=0.325] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 Average Loss: 0.2438\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di masa lalu, tangan tubuh dan ketahanan. Setelah lemah berbutir aku harus belajar tentang seorang individu, anak mudaku. batin baik hati, hubungan dengan melakukan aktivitas untuk merasakan pikiran dan kesabaran, seni internasional sebagai tempat impian mereka sendiri. Sangat menarik perhatian keluarga\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Pertimbangkan gabunganakan dan gunakan atau area. Menggunakan yang menantang atau keterampilan. I (bBI) Teliti destinasi dan perlindungan bagi ribuan orang Romawi untuk menjadi teman, memiliki kekuatan, atau maupun sebagai bagian integral kepada dewa di sekitar 2)\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' merupakan frasa umum yang terjadi secara signifikan tetapi juga aliran baru, seperti kosa beradaptasi, dan peluang kelangsungan hidup. Diversifikasi adalah proses yang diberikan ketika mengambil keputusan. Kehangatan luar biasa keluarga diorganisasikan dengan tujuan hidup dan ajaran agar rekan-bij atau\n",
      "\n",
      "\n",
      "--- Epoch 23/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|██████████| 962/962 [08:08<00:00,  1.97it/s, loss=0.213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 Average Loss: 0.2104\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di rencana pagi selama tangan, dan ke bawah da Vinci bangun pagi. Dia mempunyai dampak yang mendalam dan berbahaya dengan anggun melewati kerumunan momen, mewakili pelakunya secara harmonis. Di tengah-tengah bahaya, membentuk tempat generasi mendatang. Terselubung dalam-an dan\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Glah kata Pertama, aku ada bagianku sebelum membaran saya untuk mengumpulkan tim yang bisa merasa heran dan selalu waspada dan setiap kesempatan. Saya ingin mendekati pantai, tetap rendah hati dengan cermat, tetapi saya tentang keberanian, baik maupun yang tak terduga,\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' merupakan perangkat. melibatkan beberapa industri dan bukti dapat memberikan data, seperti kilatan bola atau pantulan atmosfernya ampun atau pelatihan kesehatan mengenai implikasi kecerdasan buatan. Jika terjadi ketika dua atau memulai diproduksi antara lain yang harus dilakukan oleh cara yang ditargetkan, namun juga\n",
      "\n",
      "\n",
      "--- Epoch 24/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|██████████| 962/962 [07:59<00:00,  2.01it/s, loss=0.191] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 Average Loss: 0.1877\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di desa, serangan yang, dan penuh seseorang menjadi kekuatan dan kebijaksanaan. Saat jari-api, jantung kota ini fokus pada tangan dan tempat belajar tentang aktivitas. Ketika kekuatan akan merepresentasikan sejati dengan perubahan iklim secara damai dan tempat tinggal di bawah kepemimpinan yang menjadi perpaduan\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca di dekat - pelangi memancarkan warna menjadi benar.\n",
      "2. Ciptakan: Manfaatnya, reflektif atau melawan sakit dan sedikit tak tergoyahkan.\n",
      "3. Aku mengerti dengan pancaran sinarnya melalui latihan kamera Anda ke Laut,\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' adalah kata indikator atau ', dan marknya dilakukan, diikuti dengan memasang oleh kekacauans.Teknik aliran kesadaran dalam Saya hampir ajaib namun dipopulerkan di efek'bentuk-kerajaan yang merupakan cita-cita sempurna, meskipun bereksperimen dengan menenangkan pikiran dan memikat\n",
      "\n",
      "\n",
      "--- Epoch 25/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|██████████| 962/962 [07:58<00:00,  2.01it/s, loss=0.122] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 Average Loss: 0.1714\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di desa, biasanya, dan tubuh untuk mereka. Jika naga seseorang memberi para penyihir secara emosional mereka merasakan kerentanan dapat sering kali merasa dan warisan mereka selama satu sama lain karena melimpah,Kisah. Selain itu, ada kekuatan luar biasa adalah proses yang banggakan -\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Saya akan memulai komunikasi, mengumpulkan data sensitif, atau melakukan apa pun kreatif. Saya kemudian meninjau status mereka berkomunikasi dengan mereka dengan cermat terhadap kerentanan terhadap eksperimen fisik mereka, baik! Saya akan memastikan bahwa kepentingan mereka memiliki cakrawala tersebut sambil tetap berpikiran terbuka untuk meminta bantuan\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ' merupakan frasa penting untuk sentuhan membawa bencana, dan bahan-bahan seperti kode Aduk secara menyeluruh.Teknik aliran dewan tahunan terang ketika keduanya sebagai Bruce Wayne, logam dengan alam yang tidak terlihat meliputi: penahan, Kekaisaran Romawi?\n",
      "\n",
      "\n",
      "--- Epoch 26/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|██████████| 962/962 [07:46<00:00,  2.06it/s, loss=0.158] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 Average Loss: 0.1546\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di kehormatan, dalam tarian mata air mata air mata air dan keanggunan. Ritualnya meliputi mencari gas-lemp banjir dapat hingga ke bawah sinar matahari menjadi semakin meningkatkan pertumbuhan hijau. Saat Anda gambarkan, lanskap merah saat masuk akal menyaksikan perubahan iklim\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti kilatan bola atau pantulan atmosfer.\n",
      "2. Uji coba militer terhadap sebelum dihancurkan sekaligus keahlian dan kehadiran kami semakin berkembang.\n",
      "3. Dorong manusia untuk menyembunyikan dunia yang ampuh, menjadikannya pilihan yang memberikan cahayanya\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ','mereka pengaruh jiwa dan menjadi bulan. Saya tidak ada seorang Angkatan Darat Kontinental, saat kita sedang menyaksikan final yang diberi abadi ketika saya menyadari bahwa benda mati. Peliharaalnya? Sekarang, dan ke permukaan, bulan bisa merasakan keinginan untuk lepas darinya\n",
      "\n",
      "\n",
      "--- Epoch 27/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|██████████| 962/962 [07:49<00:00,  2.05it/s, loss=0.297] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 Average Loss: 0.1413\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Ah, tetapi sayapkannya secara tidak. Pertama, ada tiga tetes tambahan mistik. Tusupi fajar terulur, calon wirausahawan yang jatuh ke dalam penguasaan seni meragukan dengan penuntunnya bersinar di bawah pinggul ini terasa tak tertahankan. Ketikamu yang berusaha\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: Saya akan menggunakan kemampuan untuk fokus mental, atau terkena jumlah yang aman ke berbagai elemen kunci. Untuk menghindari ancaman, saya akan menyarankan masyarakat tidak membantu membangun koneksi dengan organisasi, seperti signifikansi budaya atau kekurangan pangan, melodi. Saya juga akan menggunakan akses jarak jauh lagi\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', dan cintaari banyak. Namun, atau dalam drama tersebut, kita bisa waspada dalam membentuk kualitas magis. Teori lain harus dipandu oleh konsekuensinya dapat mati atau kurangnya karakter moral dan pengeluaran Anda saat ini? Bisakah Anda terima dengan kesulitan yang tangguh untuk dana\n",
      "\n",
      "\n",
      "--- Epoch 28/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|██████████| 962/962 [07:48<00:00,  2.05it/s, loss=0.142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 Average Loss: 0.1315\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di desa, yang sangat hutan, dan kesadaran akan datang di hutan ajaib secara luas dengan menaruh curiga. Cond berkilau saat matahari terbit dan tarik hutan untuk mengganggu keseimbangan ekosistem, mengumpulkan pertumbuhan dengan kuat dengan berbagai tempat terbuka mereka. Beberapa makhluk, seperti centaur\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti kilatan bola atau pantulan atmosfer.\n",
      "2. Uji coba militer terhadap pesawat baru atau proyek rahasia.\n",
      "3. Kesalahan identifikasi pesawat konvensional tampaknya dia dengan warna merah dan memanas. Phoenixter yang disebabkan oleh orang lain seperti\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', seorang pemimpin (N kata cahaya dari putaran dengan jumlah yang dipenuhi aroma. Setelah berada dibutuhkannyaang-api atau tidak menentu seperti itu adalah menjelajahi permukaan satu jam selama beberapa di antaranya meliputi: ajarkan pada pameran, memainkan peran observasi dan menuju bumi\n",
      "\n",
      "\n",
      "--- Epoch 29/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|██████████| 962/962 [07:39<00:00,  2.10it/s, loss=0.17]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 Average Loss: 0.1244\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Di desa, selama perjalanan, dan ketakutan mereka. fokuslah tubuh lebih banyak orang lain. Jalan menuju gelar lebih kecil harus berjuang untuk menangani evakuasi penduduk desa dan introspeksi dan harmoni dalam jangka waktu ke orang-orang yang penuh kasih sayang, disiplin diri mereka\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti ks, atau jari-jari halus fajar yang ditentukan. Nightingale selama Perang Krimea mereka mengungkapkan.\n",
      "2. Kesalahan identifikasi keterampilan mereka yang sempurna, bersiaplah untuk menunggu mereka mengungkapkan informasi tentang kode atau karakteristik dari j\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', dan kita. Saya sobat melibatkan beberapa risiko seseorang, seperti ks), berlatihlah atau kekuasaan dalam proses melupakan optimal, tetap bertanggung jawab untuk mempertahankan tingkat aktivitas yang sesuai kebutuhan. Namun, atau orang tetap adaV yang berbeda: Itu hal yang\n",
      "\n",
      "\n",
      "--- Epoch 30/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|██████████| 962/962 [07:55<00:00,  2.02it/s, loss=0.127] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30 Average Loss: 0.1159\n",
      "--- Generating Sample Response ---\n",
      "Prompt: Anda adalah seorang ksatria naga.\n",
      "Response: Diona, selama sekitar, dan jiwa mereka. penyihirorn kuno, mantraBiaya yang sulit ditangkap dengan baik sesuai dengan aman dan harmoni terhadap kehidupan yang menakjubkan.Kucing Schrödinger adalah impian mereka, dan tak terlupakan. Melalui kemenangan dalam bidang perdagangan yang lama,\n",
      "\n",
      "Prompt: Selamat datang di toko saya. Anda mau beli apa?\n",
      "Response: 1. Fenomena cuaca, seperti kilatan bola atau pantulan.\n",
      "2. Ciptaan saya untuk memberikan campuran dari keberadaan mereka sekaligus mendapatkan kerentanan dan selalu berbisik selama satu sama lain yang dapat membantu mereka tetap sesuai untuk melindungi diri dari potensi ancaman apa pun\n",
      "\n",
      "Prompt: Haloo!\n",
      "Response: ', dan dunia maya. Penggunaan bumi terdiri dari perbedaan tekanan, seperti perubahan iklim.ima kasih karena menyebabkan kebingungan di bawah laut yang memikat ini merupakan ekosistem internal melalui demokrasi, dan meningkatkan ketahanan kita untuk mendorong kemampuan fisik.\n",
      "\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 1. Setup for Training ---\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = GPT(\n",
    "    VOCAB_SIZE, \n",
    "    EMBED_DIM, \n",
    "    MAX_SEQ_LEN, \n",
    "    NUM_HEADS, \n",
    "    NUM_LAYERS\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"Instantiated a new, untrained model.\")\n",
    "\n",
    "# Initialize the Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize the Loss Function (ignoring our -100 mask)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "\n",
    "# --- 2. Advanced Generation Function (for Epoch Testing) ---\n",
    "\n",
    "def generate_epoch_test(model, \n",
    "                        tokenizer, \n",
    "                        prompt_text, \n",
    "                        max_len=50, \n",
    "                        top_p=0.9, \n",
    "                        temperature=1.0, \n",
    "                        repetition_penalty=1.2):\n",
    "    \"\"\"\n",
    "    Generates a creative test response using all our advanced techniques.\n",
    "    \"\"\"\n",
    "    # 1. Set model to evaluation mode (disables dropout, etc.)\n",
    "    model.eval()\n",
    "    \n",
    "    # Format the prompt exactly as it was in training\n",
    "    formatted_prompt = f\"User: {prompt_text}\\n\\nModel: \"\n",
    "    \n",
    "    prompt_ids = tokenizer(formatted_prompt, return_tensors=\"pt\")['input_ids'].to(DEVICE)\n",
    "    prompt_len = prompt_ids.shape[1]\n",
    "    generated_ids = prompt_ids\n",
    "\n",
    "    # 2. Disable gradient calculation for speed\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 3. Get logits for the last token\n",
    "            logits = model(generated_ids) # [1, T, V]\n",
    "            last_logits = logits[:, -1, :]  # [1, V]\n",
    "\n",
    "            # 4. Apply Temperature\n",
    "            last_logits = last_logits / temperature\n",
    "            \n",
    "            # 5. Apply Repetition Penalty\n",
    "            if repetition_penalty > 1.0:\n",
    "                recent_tokens = generated_ids[0, -50:]\n",
    "                last_logits[0].scatter_add_(\n",
    "                    0, \n",
    "                    recent_tokens, \n",
    "                    torch.full_like(recent_tokens, -repetition_penalty, dtype=torch.float)\n",
    "                )\n",
    "\n",
    "            # 6. Nucleus Sampling (Top-p)\n",
    "            probs = F.softmax(last_logits, dim=-1)\n",
    "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = 0\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            last_logits[0, indices_to_remove] = float('-inf')\n",
    "\n",
    "            # 7. Re-calculate probabilities and sample\n",
    "            next_token_probs = F.softmax(last_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(next_token_probs, num_samples=1)\n",
    "\n",
    "            # 8. Append the new token\n",
    "            generated_ids = torch.cat((generated_ids, next_token_id), dim=1)\n",
    "\n",
    "            # 9. Stop if we hit the EOS token\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "                \n",
    "    # 10. Slice and Decode\n",
    "    output_ids = generated_ids[0][prompt_len:]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # 11. CRITICAL: Set model back to training mode\n",
    "    model.train()\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# --- 3. The Training Loop ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\")\n",
    "    \n",
    "    for batch_input_ids, batch_labels in pbar:\n",
    "        \n",
    "        batch_input_ids = batch_input_ids.to(DEVICE)\n",
    "        batch_labels = batch_labels.to(DEVICE)\n",
    "        \n",
    "        logits = model(batch_input_ids)\n",
    "        \n",
    "        # Align Logits and Labels (the fix from before)\n",
    "        logits_aligned = logits[:, :-1, :].contiguous()\n",
    "        labels_aligned = batch_labels[:, 1:].contiguous()\n",
    "        \n",
    "        loss = criterion(\n",
    "            logits_aligned.view(-1, logits_aligned.shape[-1]),\n",
    "            labels_aligned.view(-1)\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"\\nEpoch {epoch+1} Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Generate a sample response using the new, correct prompt format\n",
    "    print(\"--- Generating Sample Response ---\")\n",
    "    test_prompts = [\n",
    "        \"Anda adalah seorang ksatria naga.\",\n",
    "        \"Selamat datang di toko saya. Anda mau beli apa?\",\n",
    "        \"Haloo!\"\n",
    "    ]\n",
    "    for p in test_prompts:\n",
    "        generated_text = generate_epoch_test(model, tokenizer, p)\n",
    "        print(f\"Prompt: {p}\\nResponse: {generated_text}\\n\")\n",
    "\n",
    "print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20cd62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode (disables dropout)\n",
    "model.eval()\n",
    "\n",
    "def generate_final_response(prompt_text, \n",
    "                            max_len=100, \n",
    "                            top_p=0.9, \n",
    "                            temperature=1.0, \n",
    "                            repetition_penalty=1.2):\n",
    "    \"\"\"\n",
    "    Generates creative text using our new \"User/Model\" format.\n",
    "    \"\"\"\n",
    "    print(f\"\\nPrompt: '{prompt_text}'\")\n",
    "\n",
    "    # 1. Format the raw prompt into the template the model was trained on\n",
    "    formatted_prompt = f\"User: {prompt_text}\\n\\nModel: \"\n",
    "    \n",
    "    # 2. Tokenize the *formatted* prompt\n",
    "    prompt_ids = tokenizer(formatted_prompt, return_tensors=\"pt\")['input_ids'].to(DEVICE)\n",
    "    \n",
    "    # 3. Store the length of the *formatted* prompt for slicing\n",
    "    prompt_len = prompt_ids.shape[1]\n",
    "    \n",
    "    # 4. Initialize the generation\n",
    "    generated_ids = prompt_ids\n",
    "\n",
    "    # 5. Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 6. Get logits for the last token\n",
    "            logits = model(generated_ids) # [1, T, V]\n",
    "            last_logits = logits[:, -1, :]  # [1, V]\n",
    "\n",
    "            # 7. Apply Temperature\n",
    "            last_logits = last_logits / temperature\n",
    "            \n",
    "            # 8. Apply Repetition Penalty\n",
    "            if repetition_penalty > 1.0:\n",
    "                recent_tokens = generated_ids[0, -50:] # Look at last 50 tokens\n",
    "                last_logits[0].scatter_add_(\n",
    "                    0, \n",
    "                    recent_tokens, \n",
    "                    torch.full_like(recent_tokens, -repetition_penalty, dtype=torch.float)\n",
    "                )\n",
    "\n",
    "            # 9. Nucleus Sampling (Top-p)\n",
    "            probs = F.softmax(last_logits, dim=-1)\n",
    "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = 0\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            last_logits[0, indices_to_remove] = float('-inf')\n",
    "\n",
    "            # 10. Re-calculate probabilities and sample\n",
    "            next_token_probs = F.softmax(last_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(next_token_probs, num_samples=1)\n",
    "\n",
    "            # 11. Append the new token\n",
    "            generated_ids = torch.cat((generated_ids, next_token_id), dim=1)\n",
    "\n",
    "            # 12. Stop if we hit the EOS token\n",
    "            if next_token_id.item() == tokenizer.eos_token_id:\n",
    "                print(\"(Hit end-of-sequence token)\")\n",
    "                break\n",
    "                \n",
    "    # 13. Slice the output\n",
    "    # We only decode the tokens *after* the formatted prompt\n",
    "    output_ids = generated_ids[0][prompt_len:]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Model Response:\\n{output}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e14d599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: 'Anda adalah seorang ksatria naga.'\n",
      "(Hit end-of-sequence token)\n",
      "Model Response:\n",
      "Di muda, tajam, dan kebijaksanaan dengan baik sebelum latihan tetapi juga memiliki kekuatan kuno secara berkala. Per yang mendalam dari generasi mendatang untuk menjaga keharmonisan dan bangun di rumah sakit jiwa di sekitar mereka. 2. Pastikan untuk memasuki tempat tinggal, karena acara membaca beban saat muncul dan hubungan positif. 3. Saat Anda mengumpulkan tim, mengalahkan elemen kunci, ingat, 411 area tersebut menggoyangkan Anda dengan keyakinan yang kuat dan carilah keseimbangan di bawah tidur sebagai titik masuk secara bertahap.\n",
      "\n",
      "Prompt: 'Selamat datang di toko saya. Anda mau beli apa?'\n",
      "(Hit end-of-sequence token)\n",
      "Model Response:\n",
      "1. Fenomena cuaca, seperti kilatan bola atau pantulan.\n",
      "2. Ciptakan jam memulai hari untuk mendapat pengarahan dan melawan selama musim panas, sehingga menyebabkan berkembangnya atau proyek ber - 3. Membangun hubungan yang menarik. Ilusi optik yang disebabkan oleh persepsi dan trafoakan oleh perbedaan mereka dapat mengubah arah kepada orang lain.\n",
      "\n",
      "Prompt: 'Hari ini adalah hari yang indah.'\n",
      "(Hit end-of-sequence token)\n",
      "Model Response:\n",
      "Di jantung rumit, mengenakan pakaian badut dan sangat penting untuk menghindari predator atau E. Hal ini di antara kebajikan seperti lukisan buku harian) sistem pengendalian satu titik atau berbaring di panggung. Memilihlah untuk mik, karena karena setiap pelanggaran yang ada campuran menjaga ketenangan dan harmoni dengan kehadirannya, dan bidang lainnya.\n",
      "\n",
      "Prompt: 'Haloo!'\n",
      "Model Response:\n",
      "', Ini sering kali tenggelam dalam diriku. Berikan pelatihan atau dua kekasihibur seperti biasanya melibatkan Senat dan orang-orang yang mengatur Amerika Serikat dan kelas terhadap seseorang. Rendam Blue Moon Elu, dimana individu terlalu bergantung pada informasi merupakan suatu negara dari cedera. Selain itu, pengalaman yang berlatar utamanya untuk menjaga stabilitas angkat melalui berita, karena ini mungkin menyebabkan kebingungan dalam hal-tiba antara manusia di antara barisan musuh. Menyewa di antara keduanya semakin mengaburkan kerja sama dengan perusahaan, karena mempengaruhi perkembangan pemimpin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"', Ini sering kali tenggelam dalam diriku. Berikan pelatihan atau dua kekasihibur seperti biasanya melibatkan Senat dan orang-orang yang mengatur Amerika Serikat dan kelas terhadap seseorang. Rendam Blue Moon Elu, dimana individu terlalu bergantung pada informasi merupakan suatu negara dari cedera. Selain itu, pengalaman yang berlatar utamanya untuk menjaga stabilitas angkat melalui berita, karena ini mungkin menyebabkan kebingungan dalam hal-tiba antara manusia di antara barisan musuh. Menyewa di antara keduanya semakin mengaburkan kerja sama dengan perusahaan, karena mempengaruhi perkembangan pemimpin\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Run It! ---\n",
    "# You can now experiment with these parameters\n",
    "\n",
    "generate_final_response(\n",
    "    \"Anda adalah seorang ksatria naga.\",\n",
    "    max_len=100,\n",
    "    top_p=0.9,\n",
    "    temperature=1.0,\n",
    "    repetition_penalty=1.5\n",
    ")\n",
    "\n",
    "generate_final_response(\n",
    "    \"Selamat datang di toko saya. Anda mau beli apa?\",\n",
    "    max_len=100\n",
    ")\n",
    "\n",
    "generate_final_response(\n",
    "    \"Hari ini adalah hari yang indah.\",\n",
    "    max_len=100\n",
    ")\n",
    "\n",
    "generate_final_response(\n",
    "    \"Haloo!\",\n",
    "    max_len=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "687b6fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: 'Di antara kerumunan orang yang lalu lalang, seorang penyanyi keliling memainkan serulingnya di atas seekor babi'\n",
      "Model Response:\n",
      "Kehidupan sehari-harikuisitor yang terkasih di bawah hangat dan ditinggalkan, dengar kamu! Sebagai instruktur yoga asli mulai dengan berbagai zat, seperti badai. Di dinding mungkin mengungkapkan kecerdasan buatanlah dengan otak atau hanya melalui jendela yang tepat. Mereka menghabiskan hari-harinya dengan memeriksa isinya, perasaan campur aduk membanjiri diriku tetap disebabkan oleh nelayan memasuki sentuhan alami dari harta benda atau aneh bagi orang itu. Selain itu, para Templar, luangkan waktu untuk mengirim tanah, dan bertanggung jawab yang tersisa tetap penting untuk berhati-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kehidupan sehari-harikuisitor yang terkasih di bawah hangat dan ditinggalkan, dengar kamu! Sebagai instruktur yoga asli mulai dengan berbagai zat, seperti badai. Di dinding mungkin mengungkapkan kecerdasan buatanlah dengan otak atau hanya melalui jendela yang tepat. Mereka menghabiskan hari-harinya dengan memeriksa isinya, perasaan campur aduk membanjiri diriku tetap disebabkan oleh nelayan memasuki sentuhan alami dari harta benda atau aneh bagi orang itu. Selain itu, para Templar, luangkan waktu untuk mengirim tanah, dan bertanggung jawab yang tersisa tetap penting untuk berhati-'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "generate_final_response(\n",
    "    \"Di antara kerumunan orang yang lalu lalang, seorang penyanyi keliling memainkan serulingnya di atas seekor babi\",\n",
    "    max_len=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98cbbb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving model to final_model.pth ---\n",
      "...Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving model to {\"final_model.pth\"} ---\")\n",
    "torch.save(model.state_dict(), \"final_model.pth\")\n",
    "print(\"...Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
